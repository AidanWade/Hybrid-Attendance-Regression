{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "## Libraries import and function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import missingno as msno \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "# %matplotlib widget\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error,root_mean_squared_error,mean_absolute_error,r2_score\n",
    "import matplotlib.ticker as mtick\n",
    "from CustomLibs.CustomFunctions import plot_corr_heatmap, value_to_float, fig_indexes, sqlcol\n",
    "from config import Config\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "date_val_end=Config.TEST_DATE_CUTOFF\n",
    "date_test_start=pd.to_datetime(date_val_end) + pd.DateOffset(days=1)\n",
    "\n",
    "from joypy import joyplot\n",
    "\n",
    "engine = sqlalchemy.create_engine(Config.CONN_STR)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Type Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    # Import leading variables - attributes which are known ahead of time\n",
    "    with open('.\\SQL Files\\CombineAllRawFeatures.sql', 'r') as query:\n",
    "        df_all = pd.read_sql_query(query.read(),conn)\n",
    "df_all['Date']=pd.to_datetime(df_all['Date'])\n",
    "df_all['School_Holiday']=df_all['School_Holiday'].apply(bool).astype(bool)\n",
    "df_all['Meeting_Participants']=df_all['Meeting_Participants'].apply(value_to_float).astype(float)\n",
    "df_all.head()\n",
    "\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_all.to_sql('All_Raw_Features',conn,schema='Silver',if_exists='replace',index=False,dtype=sqlcol(df_all))\n",
    "\n",
    "\n",
    "# df_electric=df_all[['Day_Electric_KWh', 'Night_Electric_KWh']]\n",
    "drop_list = [x for x in df_all.columns if x.endswith('_ori')]\n",
    "print(drop_list)\n",
    "val_list = [x.replace('_ori','') for x in drop_list]\n",
    "print(val_list)\n",
    "df_all.drop(columns=drop_list,inplace=True)\n",
    "df_all.rename(dict(zip(drop_list, val_list)),axis=1,inplace=True)\n",
    "\n",
    "# df_all.drop(columns=['Day_Electric_KWh', 'Night_Electric_KWh', 'Heat_Consumption', 'Cold_Consumption'],inplace=True)\n",
    "# df_all.rename({'Day_Electric_KWh_ori':'Day_Electric_KWh',\n",
    "#                'Night_Electric_KWh_ori':'Night_Electric_KWh',\n",
    "#                'Heat_Consumption_ori':'Heat_Consumption',\n",
    "#                'Cold_Consumption_ori':'Cold_Consumption'},axis=1,inplace=True)\n",
    "\n",
    "print(f'loaded {len(df_all.columns)} columns and {len(df_all)} rows')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# leading_features=df_all.columns[:13].tolist()\n",
    "# lagging_features=df_all.columns[14:-1].tolist()\n",
    "label_field = df_all.columns[-1]\n",
    "\n",
    "# print(leading_features)\n",
    "# print(lagging_features)\n",
    "print(label_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = msno.matrix(df_all,figsize=(20,5))\n",
    "ax1.plot()\n",
    "ax1.figure.savefig('./Output Files/Images/Data Exploration/missing_values_matrix.png',format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = msno.bar(df_all,figsize=(16,6))\n",
    "ax2.grid(visible=True,which='Major',axis='y') \n",
    "ax2.axhline(y=0.8,xmin=0,xmax=1, linewidth=2, color='r',linestyle='-',label='Cutoff')\n",
    "# print(type(ax2))\n",
    "# ax2.legend()\n",
    "# ax2.plot()\n",
    "# ax2.set_ylim(0,1.2)\n",
    "# ax2.figure.tight_layout()\n",
    "# ax2._secondary_axes.SecondaryAxis.tick_params(axis='both', which='major', labelsize=8)\n",
    "# ax2.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax2.figure.savefig('./Output Files/Images/Data Exploration/missing_values_bar.png',format='png',bbox_inches='tight')\n",
    "\n",
    "print(len(df_all))\n",
    "print(len(df_all.dropna()))\n",
    "\n",
    "print(len(df_all.set_index('Date').loc[:date_val_end]))\n",
    "print(len(df_all.set_index('Date').loc[:date_val_end].dropna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Datasets .describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.describe().to_csv('./Output Files/Text/Data Exploration/feature_description.csv')\n",
    "with open('./Output Files/Text/Data Exploration/feature_info.txt', 'w') as f:\n",
    "    df_all.info(buf=f)\n",
    "\n",
    "not_enough_data=[]\n",
    "for columnName, columnData in df_all.items():\n",
    "    if columnData.count() / len(columnData) < 0.8:\n",
    "        not_enough_data.append(columnName)\n",
    "print(not_enough_data)\n",
    "df_all.drop(columns=not_enough_data,inplace=True)\n",
    "\n",
    "# df_all.info()\n",
    "\n",
    "leading_features=df_all.columns[:11].tolist()\n",
    "lagging_features=df_all.columns[12:-1].tolist()\n",
    "label = df_all.columns[-1]\n",
    "\n",
    "print(leading_features)\n",
    "print(lagging_features)\n",
    "print(label)\n",
    "# df_all.pivot(columns='Day_Name',values='Actual_Desks_Used').describe().to_csv('./Output Files/Text/Data Exploration/attendance_by_day_description.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets .info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attendence Distribution by Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs=plt.subplots(1,2,figsize=(10,4))\n",
    "\n",
    "days_of_week=['Monday','Tuesday','Wednesday','Thursday','Friday']\n",
    "df_all['Day']=df_all['Date'].dt.day_name()\n",
    "# df_all['TestFlag']=df_all['Date']<=date_val_end\n",
    "df_all['TestFlag'] = np.where(df_all['Date']<=date_val_end, 'Train / Validation', 'Test')\n",
    "# df_all['Day_Number']=df_all['Date'].dt.day_of_week()\n",
    "\n",
    "\n",
    "sns.histplot(data=df_all,x='Actual_Desks_Used',ax=axs[0],hue='TestFlag',common_norm=False,kde=True,bins=25,stat='percent')\n",
    "axs[0].set_title(f'Distribution By Training and Test' ,fontsize=16)\n",
    "axs[0].set_xlabel('Staff on Site',fontsize=12)\n",
    "\n",
    "\n",
    "sns.histplot(data=df_all,x='Actual_Desks_Used',ax=axs[1],hue='Day',kde=True,bins=25,stat='percent',common_norm=True,element='step')\n",
    "axs[1].set_title(f'Distribution By Day' ,fontsize=16)\n",
    "axs[1].set_xlabel('Staff on Site',fontsize=12)\n",
    "\n",
    "if Config.MASK_VALUE:\n",
    "    axs[0].set_xticklabels([])\n",
    "    axs[1].set_xticklabels([])\n",
    "fig.tight_layout()\n",
    "fig.savefig('./Output Files/Images/Data Exploration/Attendance_Distribution.png',format='png',bbox_inches='tight')\n",
    "\n",
    "df_all.drop(columns='TestFlag',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "df_all['Day_Of_Week']=df_all['Date'].dt.day_of_week\n",
    "# display(df_all[['Day_Of_Week','Day']].sort_values('Day_Of_Week'))\n",
    "df_g=df_all.groupby('Day',sort=False)\n",
    "fig, axes = joyplot(df_g, column='Actual_Desks_Used', colormap=cm.Pastel1, grid=\"y\", overlap = 3, fade=False,title='Attendance Frequency Distribution By Day',linewidth=1,figsize=(6,5))\n",
    "\n",
    "#     axes.set_xticklabels([])\n",
    "for ax in axes:\n",
    "    if Config.MASK_VALUE:\n",
    "        ax.set_xticklabels([])\n",
    "    ax.set_xlabel('Staff On Site')\n",
    "\n",
    "fig.savefig('./Output Files/Images/Data Exploration/Attendance_Distribution_joyday.png',format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_g=df_all.groupby('Day',sort=False)\n",
    "df_all['TestFlag'] = np.where(df_all['Date']<=date_val_end, 'Train / Validation', 'Test')\n",
    "fig, axes = joyplot(df_all, by='TestFlag', column='Actual_Desks_Used', colormap=cm.Pastel1, grid=\"y\", overlap = 1, fade=False,title='Attendance Frequency Distribution By Dataset',linewidth=1,figsize=(6,3))\n",
    "\n",
    "#     axes.set_xticklabels([])\n",
    "for ax in axes:\n",
    "    if Config.MASK_VALUE:\n",
    "        ax.set_xticklabels([])\n",
    "    ax.set_xlabel('Staff On Site')\n",
    "\n",
    "fig.savefig('./Output Files/Images/Data Exploration/Attendance_Distribution_joydataset.png',format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attendance by Date and Day of Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1,ax1=plt.subplots(1,1,figsize=(10,4))\n",
    "fig2,ax2=plt.subplots(1,1,figsize=(10,4))\n",
    "axs=[ax1,ax2]\n",
    "df_all['Pct_On_Site']=df_all['Actual_Desks_Used']/df_all['Total_Staff']\n",
    "sns.lineplot(x='Date',y='Pct_On_Site',data = df_all,hue='Day',ax=axs[0])\n",
    "axs[0].set_title(f'Attendance by Day',fontsize=16)\n",
    "\n",
    "# sns.lineplot(x='Date',y='PctOnSite',data = df_leading,hue='DayName',ax=ax)\n",
    "df_all['Week_Number']=df_all['Date'].dt.isocalendar().week\n",
    "df_all['Year']=df_all['Date'].dt.year\n",
    "df_byweek=df_all.groupby(['Week_Number','Year'],as_index=False).agg({'Date':'min','Actual_Desks_Used':'sum','Total_Staff':'sum','Total_Leave':'sum'})\n",
    "df_byweek['Pct_On_Site']=df_byweek['Actual_Desks_Used']/df_byweek['Total_Staff']\n",
    "df_byweek['Pct_On_Site_hols']=df_byweek['Actual_Desks_Used']/(df_byweek['Total_Staff']-df_byweek['Total_Leave'])\n",
    "\n",
    "\n",
    "sns.lineplot(x='Date',y='Pct_On_Site',data = df_byweek,ax=axs[1],label='Weekly Total')\n",
    "sns.lineplot(x='Date',y='Pct_On_Site_hols',data = df_byweek,ax=axs[1],label='Weekly Total (excl Leave)')\n",
    "# axs[1].hlines(y=0.5,xmin=min(df_byweek['Date']),xmax=max(df_byweek['Date']), linewidth=1, color='r',linestyles='dashed',label='Target')\n",
    "axs[1].set_title(f'Total Attendance per Week',fontsize=16)\n",
    "\n",
    "for ax in axs:\n",
    "    \n",
    "    ax.set_ylabel('% Staff On-Site',fontsize=12)\n",
    "    ax.set_xlabel('Date',fontsize=12)\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    ax.set_ylim(0,0.6)\n",
    "    ax.grid(visible=True,which='Major',axis='both') \n",
    "    ax.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "if Config.MASK_VALUE:\n",
    "    axs[0].set_yticklabels([])\n",
    "    axs[1].set_yticklabels([])\n",
    "\n",
    "fig1.savefig('./Output Files/Images/Data Exploration/Attendance_PerDay_and_PerWeek.png',format='png',bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_silver=df_leading.merge(right=df.drop(columns=['PctOnSite','ma5','ma7','ma11']),how='left',on='Date')\n",
    "\n",
    "# fig0,ax0=plt.subplots(figsize=(12,10))\n",
    "fig1,ax1=plt.subplots(figsize=(10,10))\n",
    "fig2,ax2=plt.subplots(figsize=(10,10))\n",
    "\n",
    "args={'annot':False}\n",
    "\n",
    "# plot_corr_heatmap(df=df_ts.select_dtypes(include=np.number),ax=ax0,**args)\n",
    "droplist=['Week_Number','Year','Pct_On_Site','Car_Parking_Capacity','Motorbike_Parking_Capacity','Bike_Parking_Capacity']\n",
    "plot_corr_heatmap(df=df_all.drop(columns=droplist).select_dtypes(include=np.number),ax=ax1)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=10)\n",
    "ax1.set_title('Pearson r Correlation Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig1.savefig('./Output Files/Images/Data Exploration/Feature_Correlation.png',format='png',bbox_inches='tight')\n",
    "\n",
    "\n",
    "plot_corr_heatmap(df=df_all.drop(columns=droplist).select_dtypes(include=np.number),method='spearman',ax=ax2)\n",
    "ax2.set_title('Spearman rho Correlation Matrix')\n",
    "ax2.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.tight_layout()\n",
    "fig2.savefig('./Output Files/Images/Data Exploration/Feature_Correlation_spearman.png',format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "### Leading Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df_leading.select_dtypes(include=np.number).columns))\n",
    "fig1,axs1=plt.subplots(8,6,figsize=(8,12))\n",
    "# fig1.subplots_adjust(wspace=2)\n",
    "\n",
    "fig2,axs2=plt.subplots(12,4,figsize=(8,10))\n",
    "# fig2.subplots_adjust(wspace=0.2,hspace=0.8)\n",
    "\n",
    "# Iterate through attributes\n",
    "dont_include=['Date','Desks_Booked','Cold_Consumption','Heat_Consumption','Car_Parking_Capacity', 'Motorbike_Parking_Capacity', 'Bike_Parking_Capacity','Week_Number','Year','Day','Total_Staff','School_Holiday']\n",
    "['Total_Attendees', 'Total_Meetings', 'Air_Conditioning', 'East_Floor_Usage', 'West_Floor_Usage']\n",
    "['Date', 'Desks_Booked', 'Total_Staff', 'Min_Air_Temp', 'Max_Air_Temp', 'Rainfall', 'Windspeed', 'School_Holiday', 'Annual_Leave', 'Flexi_Leave', 'Total_Leave']\n",
    "['FTE_Count', 'Car_Parking_Occupancy', 'Car_Parking_Capacity', 'Motorbike_Parking_Occupancy', 'Motorbike_Parking_Capacity', 'Bike_Parking_Occupancy', 'Bike_Parking_Capacity', 'Daily_Transactions', 'Breakfast', 'Lunch', 'Hot_Meals', 'VPN_cnxn', 'Webex_Connections', 'Webex_Total_Participants', 'Webex_Maximum_Concurrent_Meetings', 'Total_Electric_KWh', 'Day_Electric_KWh', 'Night_Electric_KWh', 'Gas_Consumption', 'Kitchen_Usage', 'Water_Consumption', 'Cold_Consumption', 'Heat_Consumption', 'Total_Monthly_Biodegradable', 'Total_Monthly_Landfill', 'Total_Monthly_Recycable', 'Total_Monthly_Waste']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i,(columnName, columnData) in enumerate(df_all.drop(columns=dont_include).items()):#.select_dtypes(include=np.number).drop(columns=droplist).items()):\n",
    "    # Get x,y figure co-ords based on current i\n",
    "    x,y=fig_indexes(6,i)\n",
    "    try:\n",
    "    # Plot results using seaborn histplot\n",
    "        sns.boxplot(data=columnData,ax=axs1[x][y],\n",
    "                        notch=False, showcaps=True,\n",
    "                        flierprops={\"marker\": \"x\"},\n",
    "                        boxprops={\"facecolor\": (.3, .5, .7, .5)},\n",
    "                        medianprops={\"color\": \"r\", \"linewidth\": 2},)\n",
    "        if Config.MASK_VALUE:\n",
    "            axs1[x][y].set_yticklabels([])\n",
    "        x,y=fig_indexes(4,i)\n",
    "        sns.histplot(data=columnData,ax=axs2[x][y],stat='frequency',kde=True)\n",
    "        if y>0:\n",
    "            axs2[x][y].set(ylabel=None)\n",
    "        axs2[x][y].set(xlabel=None)\n",
    "        axs2[x][y].set_title(f'{columnName}',fontsize=10)\n",
    "\n",
    "        if Config.MASK_VALUE:\n",
    "            axs2[x][y].set_xticklabels([])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Remove extra ax\n",
    "for j in range(i+1,8*6):\n",
    "    x,y=fig_indexes(6,j)\n",
    "    fig1.delaxes(axs1[x,y])\n",
    "\n",
    "for j in range(i+1,12*4):\n",
    "    x,y=fig_indexes(4,j)\n",
    "    fig2.delaxes(axs2[x,y])\n",
    "\n",
    "fig1.tight_layout()\n",
    "fig2.tight_layout()\n",
    "fig1.savefig('./Output Files/Images/Data Exploration/Boxplots.png',format='png',bbox_inches='tight')\n",
    "fig2.savefig('./Output Files/Images/Data Exploration/histplots.png',format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For report version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df_leading.select_dtypes(include=np.number).columns))\n",
    "fig1,axs1=plt.subplots(1,6,figsize=(8,3))\n",
    "# fig1.subplots_adjust(wspace=2)\n",
    "\n",
    "fig2,axs2=plt.subplots(1,4,figsize=(8,2))\n",
    "# fig2.subplots_adjust(wspace=0.2,hspace=0.8)\n",
    "\n",
    "# Iterate through attributes\n",
    "dont_include=['Date','Desks_Booked','Cold_Consumption','Heat_Consumption','Car_Parking_Capacity', 'Motorbike_Parking_Capacity', 'Bike_Parking_Capacity','Week_Number','Year','Day','Total_Staff','School_Holiday']\n",
    "['Total_Attendees', 'Total_Meetings', 'Air_Conditioning', 'East_Floor_Usage', 'West_Floor_Usage']\n",
    "['Date', 'Desks_Booked', 'Total_Staff', 'Min_Air_Temp', 'Max_Air_Temp', 'Rainfall', 'Windspeed', 'School_Holiday', 'Annual_Leave', 'Flexi_Leave', 'Total_Leave']\n",
    "['FTE_Count', 'Car_Parking_Occupancy', 'Car_Parking_Capacity', 'Motorbike_Parking_Occupancy', 'Motorbike_Parking_Capacity', 'Bike_Parking_Occupancy', 'Bike_Parking_Capacity', 'Daily_Transactions', 'Breakfast', 'Lunch', 'Hot_Meals', 'VPN_cnxn', 'Webex_Connections', 'Webex_Total_Participants', 'Webex_Maximum_Concurrent_Meetings', 'Total_Electric_KWh', 'Day_Electric_KWh', 'Night_Electric_KWh', 'Gas_Consumption', 'Kitchen_Usage', 'Water_Consumption', 'Cold_Consumption', 'Heat_Consumption', 'Total_Monthly_Biodegradable', 'Total_Monthly_Landfill', 'Total_Monthly_Recycable', 'Total_Monthly_Waste']\n",
    "\n",
    "\n",
    "do_include_box=['FTE_Count','Meeting_Duration','Rainfall','Pct_On_Site','Meeting_Cnxns','Car_Parking_Occupancy']\n",
    "do_include_histo=['Hot_Meals','Day_Electric_KWh','Car_Parking_Occupancy','Annual_Leave']\n",
    "\n",
    "for i,(columnName, columnData) in enumerate(df_all[do_include_box].items()):#.select_dtypes(include=np.number).drop(columns=droplist).items()):\n",
    "    # Get x,y figure co-ords based on current i\n",
    "\n",
    "    try:\n",
    "    # Plot results using seaborn histplot\n",
    "        sns.boxplot(data=columnData,ax=axs1[i],\n",
    "                        notch=False, showcaps=True,\n",
    "                        flierprops={\"marker\": \"x\"},\n",
    "                        boxprops={\"facecolor\": (.3, .5, .7, .5)},\n",
    "                        medianprops={\"color\": \"r\", \"linewidth\": 2},)\n",
    "        if Config.MASK_VALUE:\n",
    "            axs1[i].set_yticklabels([])\n",
    "        \n",
    "\n",
    "    except:\n",
    "        pass\n",
    "fig1.suptitle('Selected Box Plots',fontsize=12,fontweight='bold')\n",
    "\n",
    "\n",
    "for i,(columnName, columnData) in enumerate(df_all[do_include_histo].items()):#.select_dtypes(include=np.number).drop(columns=droplist).items()):\n",
    "    # Get x,y figure co-ords based on current i\n",
    "\n",
    "    try:\n",
    "    # Plot results using seaborn histplot\n",
    "        sns.histplot(data=columnData,ax=axs2[i],stat='frequency',kde=True)\n",
    "        if Config.MASK_VALUE:\n",
    "            axs2[i].set_xticklabels([])\n",
    "        \n",
    "\n",
    "    except:\n",
    "        pass\n",
    "fig1.suptitle('Selected Box Plots',fontsize=12)\n",
    "fig2.suptitle('Selected Histograms',fontsize=12)\n",
    "\n",
    "\n",
    "fig1.tight_layout()\n",
    "fig2.tight_layout()\n",
    "fig1.savefig('./Output Files/Images/Data Exploration/Boxplots_onerow.png',format='png',bbox_inches='tight')\n",
    "fig2.savefig('./Output Files/Images/Data Exploration/histplots_onerow.png',format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_stats={}\n",
    "outlier_list=[]\n",
    "\n",
    "zthresh1=3.0\n",
    "zthresh2=5.0\n",
    "fig,axs=plt.subplots(20,1)\n",
    "\n",
    "i=0\n",
    "dates=df_all['Date']\n",
    "\n",
    "for columnName,columnData in df_all.drop(columns=droplist).select_dtypes(include=np.number).items():\n",
    "    zmean=np.mean(columnData.loc[lambda x : x != 0])\n",
    "    zstd=np.std(columnData.loc[lambda x : x != 0])\n",
    "    zdist = np.abs(columnData - zmean) / zstd\n",
    "    mask1 = (zthresh1 < zdist) & (zthresh2 > zdist)\n",
    "    mask2 = (zthresh2 <= zdist)\n",
    "\n",
    "    if np.sum(mask1) + np.sum(mask2) > 0:\n",
    "        # x,y=fig_indexes(2,i)\n",
    "        \n",
    "        zoutliers1 = 100*np.sum(mask1)/len(columnData)\n",
    "        zoutliers2 = 100*np.sum(mask2)/len(columnData)\n",
    "        outlier_stats[columnName]=[zmean,zstd,zoutliers1,zoutliers2,np.sum(mask1),np.sum(mask2),len(columnData),zthresh1,zthresh2]\n",
    "        if np.sum(mask2) > 0:\n",
    "            outlier_list.append(columnName)\n",
    "            # axs[i].hlines(y=zmean,xmin=min(dates),xmax=max(dates), linewidth=0.5, color='r',linestyles='dashed',label='Mean excl. 0 values')\n",
    "            # axs[i].hlines(y=zmean+zthresh2*zstd,xmin=min(dates),xmax=max(dates), linewidth=0.5, color='r',linestyles='dashed',label=f'{zthresh2} Z')\n",
    "            # axs[i].hlines(y=zmean-zthresh2*zstd,xmin=min(dates),xmax=max(dates), linewidth=0.5, color='r',linestyles='dashed',label=f'-{zthresh2} Z')\n",
    "            # axs[i].fill_between(dates, zmean - zthresh1*zstd, zmean + zthresh1*zstd, alpha=0.1,color='c',label=f'{zthresh1} x Std.Dev')\n",
    "            # axs[i].fill_between(dates, zmean + zthresh1*zstd, zmean + zthresh2*zstd, alpha=0.1,color='b',label=f'{zthresh2} x Std.Dev')\n",
    "            # axs[i].fill_between(dates, zmean - zthresh2*zstd, zmean - zthresh1*zstd, alpha=0.1,color='b')\n",
    "            axs[i].plot(dates,columnData,label=columnName)\n",
    "            axs[i].plot(dates[mask1], columnData[mask1], 'x')#, label=f'Outliers {zoutliers1+zoutliers2:.2f}%')\n",
    "            axs[i].set_title(f'{columnName}: {np.sum(mask2)} pts exceed '+ u'\\u00B1' + f'{zthresh2} Z')\n",
    "            axs[i].plot(dates[mask2], columnData[mask2], 'x', color='r')#, label=f'Outliers {zoutliers2:.2f}%')\n",
    "            axs[i].grid(visible=True,which='Major',axis='both') \n",
    "            if Config.MASK_VALUE:\n",
    "                axs[i].set_yticklabels([])\n",
    "            # axs[i].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            outlier_stats[columnName]=[zmean,zstd,zoutliers1,zoutliers2,np.sum(mask1),np.sum(mask2),len(columnData),zthresh1,zthresh2]\n",
    "\n",
    "            i=i+1\n",
    "\n",
    "# Remove extra ax\n",
    "for j in range(i,20):\n",
    "    x,y=fig_indexes(2,j)\n",
    "    fig.delaxes(axs[j])\n",
    "fig.set_size_inches(8,i*4)\n",
    "# fig.subplots_adjust(right=0.7)\n",
    "fig.tight_layout()\n",
    "# fig.savefig('./Output Files/Images/Data Exploration/zscore_outliers.png',format='png',bbox_inches='tight')\n",
    "\n",
    "print(outlier_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_stats={}\n",
    "outlier_list=[]\n",
    "\n",
    "zthresh1=3.0\n",
    "zthresh2=5.0\n",
    "fig,axs=plt.subplots(1,1,figsize=(8,3))\n",
    "axs=[axs]\n",
    "\n",
    "i=0\n",
    "dates=df_all['Date']\n",
    "\n",
    "for columnName,columnData in df_all.drop(columns=droplist).select_dtypes(include=np.number).items():\n",
    "    zmean=np.mean(columnData.loc[lambda x : x != 0])\n",
    "    zstd=np.std(columnData.loc[lambda x : x != 0])\n",
    "    zdist = np.abs(columnData - zmean) / zstd\n",
    "    mask1 = (zthresh1 < zdist) & (zthresh2 > zdist)\n",
    "    mask2 = (zthresh2 <= zdist)\n",
    "\n",
    "    if np.sum(mask1) + np.sum(mask2) > 0 and columnName=='VPN_cnxn':\n",
    "        # x,y=fig_indexes(2,i)\n",
    "        \n",
    "        zoutliers1 = 100*np.sum(mask1)/len(columnData)\n",
    "        zoutliers2 = 100*np.sum(mask2)/len(columnData)\n",
    "        outlier_stats[columnName]=[zmean,zstd,zoutliers1,zoutliers2,np.sum(mask1),np.sum(mask2),len(columnData),zthresh1,zthresh2]\n",
    "        if np.sum(mask2) > 0:\n",
    "            outlier_list.append(columnName)\n",
    "            # axs[i].hlines(y=zmean,xmin=min(dates),xmax=max(dates), linewidth=0.5, color='r',linestyles='dashed',label='Mean excl. 0 values')\n",
    "            axs[i].hlines(y=zmean+3*zstd,xmin=min(dates),xmax=max(dates), linewidth=0.5, color='orange',linestyles='dashed',label='')\n",
    "            axs[i].hlines(y=zmean-5*zstd,xmin=min(dates),xmax=max(dates), linewidth=0.5, color='r',linestyles='dashed',label='')\n",
    "            # axs[i].fill_between(dates, zmean - zthresh1*zstd, zmean + zthresh1*zstd, alpha=0.1,color='c',label=f'{zthresh1} x Std.Dev')\n",
    "            # axs[i].fill_between(dates, zmean + zthresh1*zstd, zmean + zthresh2*zstd, alpha=0.1,color='b',label=f'{zthresh2} x Std.Dev')\n",
    "            # axs[i].fill_between(dates, zmean - zthresh2*zstd, zmean - zthresh1*zstd, alpha=0.1,color='b')\n",
    "            axs[i].plot(dates,columnData,label='')\n",
    "            axs[i].plot(dates[mask1], columnData[mask1], 'x', label='> 3Z')#, label=f'Outliers {zoutliers1+zoutliers2:.2f}%')\n",
    "            axs[i].set_title(f'{columnName}: {np.sum(mask2)} pts exceed '+ u'\\u00B1' + f'{zthresh2} Z')\n",
    "            axs[i].plot(dates[mask2], columnData[mask2], 'x', color='r',label='> 5Z')#, label=f'Outliers {zoutliers2:.2f}%')\n",
    "            axs[i].grid(visible=True,which='Major',axis='both') \n",
    "            if Config.MASK_VALUE:\n",
    "                axs[i].set_yticklabels([])\n",
    "            axs[i].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            outlier_stats[columnName]=[zmean,zstd,zoutliers1,zoutliers2,np.sum(mask1),np.sum(mask2),len(columnData),zthresh1,zthresh2]\n",
    "            axs[i].set_ylabel('VPN_cnxn')\n",
    "            i=i+1\n",
    "\n",
    "# Remove extra ax\n",
    "axs[0].tick_params(axis='x', labelrotation=45)\n",
    "fig.tight_layout()\n",
    "fig.savefig('./Output Files/Images/Data Exploration/zscore_outliers.png',format='png',bbox_inches='tight')\n",
    "\n",
    "# print(outlier_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Outlier Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outlier_stats = pd.DataFrame.from_dict(outlier_stats,orient='index',columns=[' mean','std_dev','pct_z_thr1','pct_z_thr2','pts_z_thr1','pts_z_thr2','pts','thresh1','thresh2'])\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_outlier_stats.reset_index().rename(columns={\"index\":\"date\"}).to_sql('OutlierStats',conn,schema='Gold',if_exists='replace',index=False)\n",
    "    \n",
    "df_outlier_stats.to_csv('./Output Files/Text/Data Exploration/dimension_reduction_stats.csv')\n",
    "\n",
    "df_outlier_stats.loc[(df_outlier_stats['pts_z_thr1'] > 0) | (df_outlier_stats['pts_z_thr2'] > 0)].head(100)\n",
    "df_outlier_stats.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Lag Label Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower = 0.0\n",
    "# upper = 2.0\n",
    "# mu = 0.95\n",
    "# sigma = 0.1\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_access = pd.read_sql_table('AccessByDirectorate', conn,schema='Bronze')\n",
    "    df_hols = pd.read_sql_table('HolidayCalendar', conn,schema='Bronze')\n",
    "\n",
    "\n",
    "df_access=df_access.merge(df_hols[['Date','Public_Holiday']],how='left',on='Date')\n",
    "df_access=df_access.loc[df_access['Public_Holiday']!=1]\n",
    "\n",
    "df_access.dropna(subset=['Desks_Used'], inplace=True)\n",
    "df_access.drop(columns=['AccessByDirectorateID','Day','Public_Holiday'],inplace=True)\n",
    "df_access['Day_Name']=df_access['Date'].dt.day_name()\n",
    "df_access['Pct_On_Site']=df_access['Desks_Used']/df_access['Directorate_Numbers']\n",
    "df_access['Directorate']=df_access['Directorate'].str.strip()\n",
    "\n",
    "\n",
    "# rangen1=scipy.stats.truncnorm((lower-mu)/sigma,(upper-mu)/sigma,loc=mu,scale=sigma)\n",
    "# df_access['Desks_Booked_NoNoise']=df_access['Desks_Booked']\n",
    "# df_access['Desks_Booked']=df_access['Desks_Booked'].apply(lambda x: np.NaN if np.isnan(x) else int(x*rangen1.rvs(1)[0]))\n",
    "\n",
    "directorates=df_access['Directorate'].unique()\n",
    "days=df_access['Day_Name'].unique()\n",
    "\n",
    "starting_cols = df_access.columns.to_list()\n",
    "\n",
    "# print(directorates)\n",
    "per_directorate_per_day=[]\n",
    "for directorate in directorates:\n",
    "\n",
    "    df_one_directorate=df_access.loc[df_access['Directorate']==directorate].sort_values('Date')\n",
    "\n",
    "    for seq_lag in range(1,21):\n",
    "        df_one_directorate['PctOnSite_seqlag-'+str(seq_lag)]=df_one_directorate['Pct_On_Site'].shift(seq_lag)\n",
    "        # df_one_directorate['DesksUsed_seqlag-'+str(seq_lag)]=df_one_directorate['Desks_Used'].shift(seq_lag)\n",
    "\n",
    "    per_day=[]\n",
    "    for day in days:\n",
    "\n",
    "        df_one_day = df_one_directorate.loc[df_one_directorate['Day_Name']==day].sort_values('Date')\n",
    "        for week_lag in range(1,8):\n",
    "            df_one_day['PctOnSite_SameDaylag-'+str(week_lag)]=df_one_day['Pct_On_Site'].shift(week_lag)\n",
    "            # df_one_day['DesksUsed_SameDaylag-'+str(week_lag)]=df_one_day['Desks_Used'].shift(week_lag)\n",
    "            df_one_day.loc[df_one_day.index[1]:,'PctOnSite_SameDaylag-'+str(week_lag)]=df_one_day.loc[df_one_day.index[1]:,'PctOnSite_SameDaylag-'+str(week_lag)].bfill()\n",
    "            # df_one_day.loc[df_one_day.index[1]:,'DesksUsed_SameDaylag-'+str(week_lag)]=df_one_day.loc[df_one_day.index[1]:,'DesksUsed_SameDaylag-'+str(week_lag)].bfill()\n",
    "    \n",
    "        for j,win in enumerate([3,4,5,6,7,8,9,10]):\n",
    "            df_one_day['PctOnSite_ma'+str(win)]=np.nan\n",
    "            # df_one_day['DesksUsed_ma'+str(win)]=np.nan\n",
    "            for pit in range(1,len(df_one_day)):\n",
    "                ma_pct=np.mean([df_one_day.iloc[x,df_one_day.columns.get_loc('Pct_On_Site')] for x in range(max(0,pit-win),pit)])\n",
    "                # ma_used=np.mean([df_one_day.iloc[x,df_one_day.columns.get_loc('Desks_Used')] for x in range(max(0,pit-win),pit)])\n",
    "                df_one_day.iloc[pit,df_one_day.columns.get_loc('PctOnSite_ma'+str(win))]=ma_pct\n",
    "                # df_one_day.iloc[pit,df_one_day.columns.get_loc('DesksUsed_ma'+str(win))]=ma_used\n",
    "\n",
    "        per_day.append(df_one_day)\n",
    "\n",
    "\n",
    "    df_ts_one_directorate= pd.concat(per_day).sort_values(['Date'])\n",
    "    for day_lag in range(1,8):\n",
    "        df_ts_one_directorate['PctOnSite_diff-'+str(day_lag)]=df_ts_one_directorate['PctOnSite_seqlag-'+str(day_lag)] - df_ts_one_directorate['PctOnSite_ma5'].shift(day_lag)\n",
    "    \n",
    "    per_directorate_per_day.append(df_ts_one_directorate)\n",
    "        \n",
    "# print(len(per_directorate_per_day))\n",
    "df_ts_by_directorate = pd.concat(per_directorate_per_day).sort_values(['Date','Directorate'])\n",
    "# print(df_ts_by_directorate.info())\n",
    "pct_cols=[x for x in df_ts_by_directorate.columns.to_list()[len(starting_cols)-1:] if x.startswith('PctOnSite_') ]\n",
    "# print(pct_cols)\n",
    "# num_cols=[x for x in df_ts_by_directorate.columns.to_list()[len(starting_cols)-1:] if x.startswith('DesksUsed_') ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_ts_by_directorate[starting_cols+pct_cols].to_sql('Moving_Averages_By_Directorate',conn,schema='Silver',if_exists='replace',index=False,dtype=sqlcol(df_ts_by_directorate))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = joyplot(df_access, by='Directorate', column='Pct_On_Site', colormap=cm.autumn_r, grid=\"y\", overlap = 1, fade=False,title='Attendance Frequency Distribution By Directorate',linewidth=1,figsize=(6,6))\n",
    "# fig, axes = joyplot(df_access, by='Directorate', column='Pct_On_Site', ylabels=False, xlabels=False, \n",
    "#                           grid=False, fill=False, background='k', linecolor=\"w\", linewidth=1,\n",
    "#                           legend=False, overlap=1.5, figsize=(6,5))\n",
    "\n",
    "# for a in axes[:-1]:\n",
    "#     axes[-1].set_xlim([-2,2]) \n",
    "axes[-1].set_xlim([0,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summed_by_directorate=df_access.groupby('Date').sum()\n",
    "df_summed_by_directorate['Pct_On_Site']=df_summed_by_directorate['Desks_Used']/df_summed_by_directorate['Directorate_Numbers']\n",
    "df_summed_by_directorate['Day_Name']=df_summed_by_directorate.index.day_name()\n",
    "df_summed_by_directorate=df_summed_by_directorate[['Day_Name','Pct_On_Site']]\n",
    "\n",
    "starting_cols = df_summed_by_directorate.columns.to_list()\n",
    "\n",
    "days=df_summed_by_directorate['Day_Name'].unique()\n",
    "\n",
    "\n",
    "for seq_lag in range(1,21):\n",
    "    df_summed_by_directorate['PctOnSite_seqlag-'+str(seq_lag)]=df_summed_by_directorate['Pct_On_Site'].shift(seq_lag)\n",
    "    df_summed_by_directorate['PctOnSite_seqlag-'+str(seq_lag)]=df_summed_by_directorate['PctOnSite_seqlag-'+str(seq_lag)].bfill()\n",
    "\n",
    "per_day=[]\n",
    "for day in days:\n",
    "\n",
    "    df_one_day = df_summed_by_directorate.loc[df_summed_by_directorate['Day_Name']==day].sort_index()\n",
    "    \n",
    "\n",
    "    for week_lag in range(1,8):\n",
    "        df_one_day['PctOnSite_SameDaylag-'+str(week_lag)]=df_one_day['Pct_On_Site'].shift(week_lag)\n",
    "        # df_one_day['DesksUsed_SameDaylag-'+str(week_lag)]=df_one_day['Desks_Used'].shift(week_lag)\n",
    "        df_one_day.loc[df_one_day.index[1]:,'PctOnSite_SameDaylag-'+str(week_lag)]=df_one_day.loc[df_one_day.index[1]:,'PctOnSite_SameDaylag-'+str(week_lag)].bfill()\n",
    "        # df_one_day.loc[df_one_day.index[1]:,'DesksUsed_SameDaylag-'+str(week_lag)]=df_one_day.loc[df_one_day.index[1]:,'DesksUsed_SameDaylag-'+str(week_lag)].bfill()\n",
    "\n",
    "    for j,win in enumerate([3,4,5,6,7,8,9,10]):\n",
    "        df_one_day['PctOnSite_ma'+str(win)]=np.nan\n",
    "        # df_one_day['DesksUsed_ma'+str(win)]=np.nan\n",
    "        for pit in range(1,len(df_one_day)):\n",
    "            ma_pct=np.mean([df_one_day.iloc[x,df_one_day.columns.get_loc('Pct_On_Site')] for x in range(max(0,pit-win),pit)])\n",
    "            # ma_used=np.mean([df_one_day.iloc[x,df_one_day.columns.get_loc('Desks_Used')] for x in range(max(0,pit-win),pit)])\n",
    "            df_one_day.iloc[pit,df_one_day.columns.get_loc('PctOnSite_ma'+str(win))]=ma_pct\n",
    "            # df_one_day.iloc[pit,df_one_day.columns.get_loc('DesksUsed_ma'+str(win))]=ma_used\n",
    "\n",
    "    per_day.append(df_one_day)\n",
    "\n",
    "df_ts_by_day = pd.concat(per_day).sort_index()\n",
    "\n",
    "for day_lag in range(1,8):\n",
    "    df_ts_by_day['PctOnSite_diff-'+str(day_lag)]=df_ts_by_day['PctOnSite_seqlag-'+str(day_lag)] - df_ts_by_day['PctOnSite_ma5'].shift(day_lag)\n",
    "\n",
    "pct_cols=[x for x in df_ts_by_day.columns.to_list()[len(starting_cols)-1:] if x.startswith('PctOnSite_') ]\n",
    "with engine.connect() as conn:\n",
    "    df_ts_by_day[starting_cols+pct_cols].dropna().drop(columns='Day_Name').to_sql('Moving_Averages_By_Day',conn,schema='Silver',if_exists='replace',dtype=sqlcol(df_ts_by_day))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Average Prediction Quality by Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=['Monday','Tuesday','Wednesday','Thursday','Friday']\n",
    "fig,axs=plt.subplots(5,1,figsize=(20,20),sharex=False)\n",
    "\n",
    "for i,day in enumerate(days):\n",
    "    #Create a new DF per day\n",
    "    \n",
    "    df=df_ts_by_day.loc[df_ts_by_day['Day_Name']==day].dropna()\n",
    "    \n",
    "    sns.lineplot(data=df,x='Date',y='Pct_On_Site',label='Actual Attendance',ax=axs[i],linewidth = 2)\n",
    "    for j,win in enumerate([5,6,7,8,9]):\n",
    "        col='PctOnSite_ma' + str(win)\n",
    "        rms = root_mean_squared_error(df['Pct_On_Site'], df[col])\n",
    "        mae = mean_absolute_error(df['Pct_On_Site'], df[col])\n",
    "        r2 = r2_score(df['Pct_On_Site'], df[col])\n",
    "        sns.lineplot(data=df,x='Date',y=col,ax=axs[i],label=f'{str(win)} day MA',linewidth = 1.0,dashes=(2,2))\n",
    "        \n",
    "\n",
    "    axs[i].set_title(f'Moving Averages for Attendance on {day}' ,fontsize=12)\n",
    "    axs[i].set_ylabel('% Staff On-Site',fontsize=10)\n",
    "    axs[i].set_xlabel('Date',fontsize=10)\n",
    "    axs[i].yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    axs[i].set_ylim(0,0.6)\n",
    "    axs[i].grid(visible=True,which='Major',axis='both') \n",
    "    axs[i].legend(loc='upper left')\n",
    "    axs[i].legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "\n",
    "    if Config.MASK_VALUE:\n",
    "        axs[i].set_yticklabels([])\n",
    "\n",
    "\n",
    "axs[i].tick_params(axis='x', labelrotation=45)\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('./Output Files/Images/Data Exploration/MovingAverages.png',format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Output Files/Text/Data Exploration/timeshifted_info.txt', 'w') as f:\n",
    "    df_ts_by_day.info(buf=f)\n",
    "    \n",
    "# df_ts.describe().to_csv('./Output Files/Text/Data Exploration/timeshifted_attendance.csv')\n",
    "# msno.matrix(df_ts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig0,ax0=plt.subplots(figsize=(12,10))\n",
    "args={'annot':False}\n",
    "plot_corr_heatmap(df=df_ts_by_day.select_dtypes(include=np.number),ax=ax0,**args)\n",
    "fig0.savefig('.\\\\Output Files\\\\Images\\\\Data Exploration\\\\Timeseries_Correlation.png',format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(12,3))  \n",
    "\n",
    "y=df_all.set_index('Date')[label_field]\n",
    "\n",
    "_ = ax.plot(y)\n",
    "\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(gap=0, max_train_size=None, n_splits=10, test_size=10)\n",
    "TimeSeriesSplit(gap=0, max_train_size=30, n_splits=4, test_size=None)\n",
    "boundaries=[]\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(y[:date_val_end])):\n",
    "\n",
    "    y_train=y.iloc[train_index]\n",
    "    y_test=y.iloc[test_index]\n",
    "    boundaries.append(y_test.index[0])\n",
    "    boundaries.append(y_test.index[-1])\n",
    "ax.set_ylim(min(y)*1.1, max(y)*1.1)\n",
    "ax.set_xlim(min(y.index), max(y.index))\n",
    "for i in range(10):\n",
    "    ax.vlines(boundaries[i*2], max(y)*1.1, min(y)*1.1, colors='tab:pink', linestyles='solid', label='')\n",
    "# ax.vlines(boundaries[2], max(y)*1.1, min(y)*1.1, colors='tab:pink', linestyles='solid', label='')\n",
    "# ax.vlines(boundaries[4], max(y)*1.1, min(y)*1.1, colors='tab:pink', linestyles='solid', label='')\n",
    "# ax.vlines(boundaries[6], max(y)*1.1, min(y)*1.1, colors='tab:pink', linestyles='solid', label='')\n",
    "ax.axvspan(date_test_start, y.index[-1],color='c',alpha=0.2,label=f'Hold Out ({len(y[date_test_start:])} pts)')\n",
    "ax.vlines(date_test_start, max(y)*1.1, min(y)*1.1, colors='c', linestyles='solid', label='')\n",
    "ax.vlines(y.index[-1], max(y)*1.1, min(y)*1.1, colors='c', linestyles='solid', label='')\n",
    "ax.axvspan(boundaries[0], boundaries[-1],color='tab:pink',alpha=0.2,label=f'10 * 10pt Cross Validation')\n",
    "ax.set_ylabel('Daily Attendance')\n",
    "ax.set_xlabel('Date')\n",
    "if Config.MASK_VALUE:\n",
    "    ax.set_yticklabels([])\n",
    "ax.set_title('Validation and Test Regions')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig('./Output Files/Images/Data Exploration/TimeSeriesCV.png',format='png',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desks Books versus Actual Attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=['Thursday','Friday']\n",
    "fig,axs=plt.subplots(2,1,figsize=(8,5),sharex=True)\n",
    "\n",
    "for i,day in enumerate(days):\n",
    "    #Create a new DF per day\n",
    "    \n",
    "    df=df_all.loc[df_all['Day']==day][['Date','Actual_Desks_Used','Desks_Booked']].dropna()\n",
    "    \n",
    "    sns.lineplot(data=df,x='Date',y='Actual_Desks_Used',label='Actual Attendance',ax=axs[i],linewidth = 2)\n",
    "    sns.lineplot(data=df,x='Date',y='Desks_Booked',label='Desks Booked',ax=axs[i],linewidth = 2)\n",
    "    \n",
    "    if Config.MASK_VALUE:\n",
    "        axs[i].set_yticklabels([])\n",
    "\n",
    "    axs[i].set_title(f'Desks Booked Versus Actual Attendance: {day}',fontsize=11)\n",
    "    axs[i].legend(loc='upper left')\n",
    "    axs[i].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    # axs[i].tick_params(axis='x', labelrotation=45, labelsize=10)\n",
    "    axs[i].grid(visible=True,which='Major',axis='both') \n",
    "\n",
    "    \n",
    "    axs[i].set_ylabel('Staff On Site')\n",
    "\n",
    "axs[1].tick_params(axis='x', labelrotation=45, labelsize=10)\n",
    "fig.tight_layout()\n",
    "fig.savefig('./Output Files/Images/Data Exploration/Booked_Versus_Used.png',format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_rmse=root_mean_squared_error(df_all['Actual_Desks_Used']/df_all['Total_Staff'],df_all['Desks_Booked']/df_all['Total_Staff'])\n",
    "print(metric_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=['Monday','Tuesday','Wednesday','Thursday','Friday']\n",
    "fig,axs=plt.subplots(5,1,figsize=(15,10),sharex=True)\n",
    "\n",
    "for i,day in enumerate(days):\n",
    "    #Create a new DF per day\n",
    "    \n",
    "    df=df_all.loc[df_all['Day']==day][['Date','Actual_Desks_Used','Desks_Booked']].dropna()\n",
    "    \n",
    "    sns.lineplot(data=df,x='Date',y='Actual_Desks_Used',label='Actual Attendance',ax=axs[i],linewidth = 2)\n",
    "    sns.lineplot(data=df,x='Date',y='Desks_Booked',label='Desks Booked',ax=axs[i],linewidth = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
