{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import missingno as msno \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "# %matplotlib widget\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error,root_mean_squared_error,mean_absolute_error,r2_score\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error,explained_variance_score,r2_score\n",
    "import matplotlib.ticker as mtick\n",
    "from CustomLibs.CustomFunctions import plot_corr_heatmap, value_to_float, fig_indexes, sqlcol\n",
    "from config import Config\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "from CustomLibs.MultiPipe import MultiPipe\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "\n",
    "date_val_end=Config.TEST_DATE_CUTOFF\n",
    "date_test_start=pd.to_datetime(date_val_end) + pd.DateOffset(days=1)\n",
    "\n",
    "\n",
    "engine = sqlalchemy.create_engine(Config.CONN_STR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    df_access = pd.read_sql_table('Moving_Averages_By_Day', conn,schema='Silver')\n",
    "df_access = df_access.set_index('Date').loc[:date_val_end]\n",
    "\n",
    "y=df_access['Pct_On_Site']\n",
    "\n",
    "pds=MultiPipe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlags=[x for x in df_access.columns if x.startswith('PctOnSite_seqlag')]\n",
    "X=df_access[seqlags]\n",
    "\n",
    "pds.AddPreProc(RobustScaler(),'pp')\n",
    "pds.PurgeQCSet('Sequential Lag QC')\n",
    "pds.AddQCSet('pp','Sequential Lag QC')\n",
    "for lookback in range(1,len(seqlags[:8])+1):\n",
    "    label = 'seqlag_' + str(lookback)\n",
    "    _ = pds.CalculateScores('Sequential Lag QC','pp','Lag ' + str(lookback),X[seqlags[:lookback]],y)\n",
    "\n",
    "# mavgs=[x for x in df_access.columns if x.startswith('PctOnSite_ma')]\n",
    "# X=df_access[mavgs]\n",
    "# pds.AddQCSet('pp','Moving Average QC')\n",
    "# for lookback in range(1,len(mavgs)+1):\n",
    "#     label = 'movavg_' + str(lookback)\n",
    "#     _ = pds.CalculateScores('Moving Average QC','pp',mavgs[lookback-1],X[mavgs[:lookback]],y)\n",
    "\n",
    "# daylags=[x for x in df_access.columns if x.startswith('PctOnSite_SameDay')]\n",
    "# X=df_access[daylags]\n",
    "# pds.AddQCSet('pp','Same Day QC')\n",
    "# for lookback in range(1,len(daylags)+1):\n",
    "#     label = 'daylag_' + str(lookback)\n",
    "#     _ = pds.CalculateScores('Same Day QC','pp',daylags[lookback-1],X[daylags[:lookback]],y)\n",
    "\n",
    "\n",
    "# difflags=[x for x in df_access.columns if x.startswith('PctOnSite_diff')]\n",
    "# X=df_access[seqlags[:4] +daylags[:4] +mavgs[:4] + difflags]\n",
    "# pds.PurgeQCSet('Diff QC')\n",
    "# pds.AddQCSet('pp','Diff QC')\n",
    "# # _ = pds.CalculateScores('Diff QC','pp','3seq',X[seqlags[:3] ],y)\n",
    "# _ = pds.CalculateScores('Diff QC','pp','3seq_3week',X[seqlags[:3] +daylags[:3] ],y)\n",
    "# _ = pds.CalculateScores('Diff QC','pp','3seq_3week_1ma',X[seqlags[:3] +daylags[:3] +[mavgs[0]]],y)\n",
    "# for lookback in range(1,len(difflags)+1):\n",
    "#     label = 'diff_' + str(lookback)\n",
    "#     _ = pds.CalculateScores('Diff QC','pp',difflags[lookback-1],X[seqlags[:4] +daylags[:4] +[mavgs[0]] +difflags[:lookback]],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pds.GetScores(metric_keys=['R^2 Score','RMS Error','Mean Absolute Error'],verbose=False)\n",
    "fig1,axs1=plt.subplots(1,len(pds.active_metrics),figsize=(0.5+5*len(pds.active_metrics),4))  \n",
    "pds.GraphScores('Sequential Lag QC',axs1)\n",
    "# axs1[0].set_ylim(0.015,0.03)\n",
    "# axs1[1].set_ylim(0.02,0.04)\n",
    "# axs1[2].set_ylim(0.9,1.0)\n",
    "fig1.suptitle('Impact of Adding Auto-Regressive Lags on Regression Model Accuracy',fontsize=12,fontweight='bold')\n",
    "fig1.tight_layout()\n",
    "fig1.savefig('./Output Files/Images/Feature Engineering/Seq_Lag_Metrics.png',format='png',bbox_inches='tight')\n",
    "\n",
    "fig2,axs2=plt.subplots(1,len(pds.active_metrics),figsize=(0.5+5*len(pds.active_metrics),4))  \n",
    "pds.GraphScores('Moving Average QC',axs2)\n",
    "fig2.tight_layout()\n",
    "fig2.savefig('./Output Files/Images/Feature Engineering/MovingAverage_Metrics.png',format='png',bbox_inches='tight')\n",
    "\n",
    "fig3,axs3=plt.subplots(1,len(pds.active_metrics),figsize=(0.5+5*len(pds.active_metrics),4))  \n",
    "pds.GraphScores('Same Day QC',axs3)\n",
    "fig3.tight_layout()\n",
    "fig3.savefig('./Output Files/Images/Feature Engineering/SameDay_Metrics.png',format='png',bbox_inches='tight')\n",
    "\n",
    "fig4,axs4=plt.subplots(1,len(pds.active_metrics),figsize=(0.5+5*len(pds.active_metrics),4))  \n",
    "pds.GraphScores('Diff QC',axs4)\n",
    "fig4.tight_layout()\n",
    "fig4.savefig('./Output Files/Images/Feature Engineering/Diff_Metrics.png',format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs=plt.subplots(1,2,figsize=(10,4))  \n",
    "\n",
    "# _ = plot_acf(y,ax=axs[0][0])\n",
    "# _ = plot_pacf(y,ax=axs[0][1])\n",
    "\n",
    "_ = plot_acf(y.diff().dropna(),ax=axs[0])\n",
    "_ = plot_pacf(y.diff().dropna(),ax=axs[1])\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('Lags')\n",
    "axs[0].set_ylabel('ACF Value')\n",
    "_ = axs[1].set_ylabel('PACF Value')\n",
    "\n",
    "fig.suptitle('Partial and Full Autocorrelation Functions',fontsize=12,fontweight='bold')\n",
    "fig.tight_layout()\n",
    "fig.savefig('./Output Files/Images/Data Exploration/acf_pacf.png',format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(y)\n",
    "print(result[0])\n",
    "print(result[1])\n",
    "\n",
    "result = adfuller(y.diff().dropna())\n",
    "print(result[0])\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/complete-guide-to-sarimax-in-python/\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    " \n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import pmdarima as pm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "result = seasonal_decompose(y, model='multiplicative', period=5)\n",
    "trend = result.trend.dropna()\n",
    "seasonal = result.seasonal.dropna()\n",
    "residual = result.resid.dropna()\n",
    "\n",
    "# Plot the decomposed components\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(y, label='Original Series')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(trend, label='Trend')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(seasonal, label='Seasonal')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(residual, label='Residuals')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    df_preproc = pd.read_sql_table('Preprocessed_Features', conn,schema='Silver')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = [x for x in df_preproc.columns if x.startswith('PctOnSite_')]\n",
    "df=df_preproc.loc[:date_val_end].drop(columns=drop_col).set_index('Date')\n",
    "df.head()\n",
    "\n",
    "SARIMAX_model = pm.auto_arima(df['Pct_On_Site'], exogenous=df_access.drop(columns=['Pct_On_Site'],),\n",
    "                           start_p=1, start_q=1,\n",
    "                           test='adf',\n",
    "                           max_p=3, max_q=3, m=5,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=None, D=1,\n",
    "                           trace=False,\n",
    "                           error_action='ignore',\n",
    "                           suppress_warnings=True,\n",
    "                           stepwise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def sarimax_forecast(SARIMAX_model, periods=24):\n",
    "    # Forecast\n",
    "    n_periods = periods\n",
    " \n",
    "    forecast_df = df_preproc.set_index('Date').sort_index().loc[date_test_start:].drop(columns=drop_col).reset_index()\n",
    " \n",
    "    fitted, confint = SARIMAX_model.predict(n_periods=n_periods,\n",
    "                                            return_conf_int=True,\n",
    "                                            exogenous=forecast_df.drop(columns='Pct_On_Site'))\n",
    "    index_of_fc = forecast_df.index\n",
    "    print(max(df.index))\n",
    "    # make series for plotting purpose\n",
    "    fitted_series = pd.Series(fitted, index=index_of_fc)\n",
    "    lower_series = pd.Series(confint[:, 0], index=index_of_fc)\n",
    "    upper_series = pd.Series(confint[:, 1], index=index_of_fc)\n",
    " \n",
    "    # Plot\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(df[\"Pct_On_Site\"], color='#1f76b4')\n",
    "    plt.plot(fitted_series, color='darkgreen')\n",
    "    plt.fill_between(lower_series.index,\n",
    "                     lower_series,\n",
    "                     upper_series,\n",
    "                     color='k', alpha=.15)\n",
    " \n",
    "    plt.title(\"SARIMAX - Forecast of Staff On Site\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "sarimax_forecast(SARIMAX_model, periods=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from CustomLibs.CustomTransformers import SpikeRemover, DailyMeanImputer, filtered_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from imblearn.pipeline import Pipeline \n",
    "# from imblearn          import FunctionSampler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_raw = pd.read_sql_table('All_Raw_Features', conn,schema='Bronze')\n",
    "df_raw.set_index('Date',inplace=True)\n",
    "df_raw.columns = df_raw.columns.astype(str)\n",
    "df_raw.columns = [str(x) for x in df_raw.columns]\n",
    "\n",
    "drop_list = [x for x in df_raw.columns if x.endswith('_ori')]\n",
    "\n",
    "df_raw.drop(columns=drop_list,inplace=True)\n",
    "\n",
    "zthresh=5\n",
    "\n",
    "outlier_feature_list=['Heat_Consumption','Cold_Consumption','Webex_Connections','Webex_Total_Participants','FTE_Count']\n",
    "dezero_feature_list = ['VPN_cnxn','Webex_Connections','Webex_Total_Participants','Webex_Maximum_Concurrent_Meetings','Day_Electric_KWh','Night_Electric_KWh']\n",
    "\n",
    "# outlier_feature_list_ext = [x + '_onedayago' for x in outlier_feature_list] + [x + '_oneweekago' for x in outlier_feature_list] \n",
    "# dezero_feature_list_ext = [x + '_onedayago' for x in dezero_feature_list] + [x + '_oneweekago' for x in dezero_feature_list] \n",
    "\n",
    "despike_transformer=ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('5z_despike',SpikeRemover(cutvalue=5,cutmode='zthresh'),outlier_feature_list)\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "dezero_transformer=ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('dezero',SpikeRemover(cutvalue=0,cutmode='value'),dezero_feature_list)\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "df_all_dspike = despike_transformer.set_output(transform='pandas').fit_transform(df_raw)\n",
    "df_all_dzero = dezero_transformer.set_output(transform='pandas').fit_transform(df_all_dspike)\n",
    "\n",
    "\n",
    "args={'annot':True}\n",
    "fig1,ax1=plt.subplots(figsize=(25,25))\n",
    "plot_corr_heatmap(df=df_all_dzero,ax=ax1,**args)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
