{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "## Common Libray Definitions\n",
    "\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Custom Library Definitions\n",
    "from CustomLibs.CustomFunctions import plot_corr_heatmap, plot_permutation_importance, sqlcol,save_to_file,load_from_file\n",
    "from config import Config\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler,SplineTransformer,OneHotEncoder\n",
    "\n",
    "from CustomLibs.CustomTransformers import filtered_transformer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from CustomLibs.MultiPipe import MultiPipe\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "## SQL Store Definition\n",
    "engine = sqlalchemy.create_engine(Config.CONN_STR)\n",
    "\n",
    "date_val_end=Config.TEST_DATE_CUTOFF\n",
    "date_test_start=pd.to_datetime(date_val_end) + pd.DateOffset(days=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    df_preproc = pd.read_sql_table('Preprocessed_Features', conn,schema='Gold')\n",
    "    df_feature_ranks = pd.read_sql_table('PermutationFeatureRanks', conn,schema='Gold')\n",
    "\n",
    "df_preproc.set_index('Date',inplace=True)\n",
    "df_preproc.columns = [str(x) for x in df_preproc.columns]\n",
    "label_field = df_preproc.columns[-1]\n",
    "\n",
    "X=df_preproc.sort_index().loc[:date_val_end].drop(columns=label_field)\n",
    "y=df_preproc[label_field].sort_index().loc[:date_val_end]\n",
    "\n",
    "X_test=df_preproc.sort_index().loc[date_test_start:].drop(columns=label_field)\n",
    "y_test=df_preproc[label_field].sort_index().loc[date_test_start:]\n",
    "\n",
    "pds=MultiPipe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [0.6,0.8,1.0]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 90, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'randomforestregressor__n_estimators': n_estimators,\n",
    "               'randomforestregressor__max_features': max_features,\n",
    "               'randomforestregressor__max_depth': max_depth,\n",
    "               'randomforestregressor__min_samples_split': min_samples_split,\n",
    "               'randomforestregressor__min_samples_leaf': min_samples_leaf,\n",
    "            #    'randomforestregressor__bootstrap': bootstrap\n",
    "               }\n",
    "\n",
    "print('\\nParameters for random search:')\n",
    "for k,v in random_grid.items():\n",
    "    print(f'{k}: {v}')\n",
    "\n",
    "\n",
    "scoring = {'Mean Absolute Error': 'neg_mean_absolute_error', 'RMS Error': 'neg_root_mean_squared_error','R^2 Score':'r2'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if Config.REGEN_RANDOM_SEARCH_RF:\n",
    "\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf_reg = make_pipeline(filtered_transformer(X.columns.tolist()),RandomForestRegressor())\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = rf_reg, param_distributions = random_grid, n_iter = 300, cv = pds.CV, verbose=2, scoring=scoring, refit='RMS Error', random_state=43, n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    rf_random.fit(X, y)\n",
    "\n",
    "    print(f'Best parameters for RF,  (CV score={rf_random.best_score_:.3f}):',end='')\n",
    "    print(rf_random.best_params_)\n",
    "\n",
    "    rf_random_search_parameters={}\n",
    "    for p,v in rf_random.best_params_.items():\n",
    "        rf_random_search_parameters[p.replace('randomforestregressor__','')]=v\n",
    "    save_to_file(rf_random_search_parameters,'rf_random_search_parameters')\n",
    "\n",
    "else:\n",
    "    rf_random_search_parameters = load_from_file('rf_random_search_parameters')\n",
    "for k,v in rf_random_search_parameters.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.REGEN_RANDOM_SEARCH_RF_TXX:\n",
    "    feat_ranks = df_feature_ranks.sort_values('Mean Rank')['Feature'].to_list()[:20]\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf_reg_t20 = make_pipeline(filtered_transformer(X[feat_ranks].columns.tolist()),RandomForestRegressor())\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random_t20 = RandomizedSearchCV(estimator = rf_reg_t20, param_distributions = random_grid, n_iter = 300, cv = pds.CV, verbose=2, scoring=scoring, refit='RMS Error', random_state=43, n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    rf_random_t20.fit(X[feat_ranks], y)\n",
    "\n",
    "    print(f'Best parameters for RF,  (CV score={rf_random_t20.best_score_:.3f}):',end='')\n",
    "    print(rf_random_t20.best_params_)\n",
    "\n",
    "    rf_random_search_parameters_t20={}\n",
    "    for p,v in rf_random_t20.best_params_.items():\n",
    "        rf_random_search_parameters_t20[p.replace('randomforestregressor__','')]=v\n",
    "    save_to_file(rf_random_search_parameters_t20,'rf_random_search_parameters_t20')\n",
    "\n",
    "else:\n",
    "    rf_random_search_parameters_t20 = load_from_file('rf_random_search_parameters_t20')\n",
    "for k,v in rf_random_search_parameters_t20.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# n_estimators = [100,150,200,250,300,350]\n",
    "n_estimators = [125, 275,325,375]\n",
    "# Number of features to consider at every split\n",
    "max_features = [0.5,0.6,0.7]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [40,50,60,None]\n",
    "# max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [4,5,6,7]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2,3]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "search_grid = {'randomforestregressor__n_estimators': n_estimators,\n",
    "               'randomforestregressor__max_features': max_features,\n",
    "               'randomforestregressor__max_depth': max_depth,\n",
    "               'randomforestregressor__min_samples_split': min_samples_split,\n",
    "               'randomforestregressor__min_samples_leaf': min_samples_leaf,\n",
    "               'randomforestregressor__bootstrap': bootstrap\n",
    "               }\n",
    "\n",
    "print('\\nParameters for exhaustive search:')\n",
    "for k,v in search_grid.items():\n",
    "    print(f'{k}: {v}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if Config.REGEN_GRID_SEARCH_RF:\n",
    "    rf_reg = make_pipeline(filtered_transformer(X.columns.tolist()),RandomForestRegressor())\n",
    "\n",
    "    rf_gsearch = GridSearchCV(rf_reg, search_grid, scoring=scoring, refit='RMS Error',cv=pds.CV,n_jobs=-1,verbose=10)\n",
    "    rf_gsearch.fit(X, y)\n",
    "    print(f'Best parameters for RF,  (CV score={rf_gsearch.best_score_:.3f}):',end='')\n",
    "    print(rf_gsearch.best_params_)\n",
    "\n",
    "    rf_grid_search_parameters={}\n",
    "    for p,v in rf_gsearch.best_params_.items():\n",
    "        rf_grid_search_parameters[p.replace('randomforestregressor__','')]=v\n",
    "    save_to_file(rf_grid_search_parameters,'rf_grid_search_parameters')\n",
    "\n",
    "else:\n",
    "    rf_grid_search_parameters = load_from_file('rf_grid_search_parameters')\n",
    "\n",
    "for k,v in rf_grid_search_parameters.items():\n",
    "    print(f'{k}: {v}')\n",
    "\n",
    "# rf_grid_search_parameters['n_estimators']=150\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.REGEN_GRID_SEARCH_RF_TXX:\n",
    "    feat_ranks = df_feature_ranks.sort_values('Mean Rank')['Feature'].to_list()[:20]\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf_reg_t20 = make_pipeline(filtered_transformer(X[feat_ranks].columns.tolist()),RandomForestRegressor())\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_grid_t20 = GridSearchCV(rf_reg_t20, search_grid, scoring=scoring, refit='RMS Error',cv=pds.CV,n_jobs=-1,verbose=10)\n",
    "    # Fit the random search model\n",
    "    rf_grid_t20.fit(X[feat_ranks], y)\n",
    "\n",
    "    print(f'Best parameters for RF,  (CV score={rf_grid_t20.best_score_:.3f}):',end='')\n",
    "    print(rf_grid_t20.best_params_)\n",
    "\n",
    "    rf_grid_search_parameters_t20={}\n",
    "    for p,v in rf_grid_t20.best_params_.items():\n",
    "        rf_grid_search_parameters_t20[p.replace('randomforestregressor__','')]=v\n",
    "    save_to_file(rf_grid_search_parameters_t20,'rf_grid_search_parameters_t20')\n",
    "\n",
    "else:\n",
    "    rf_grid_search_parameters_t20 = load_from_file('rf_grid_search_parameters_t20')\n",
    "for k,v in rf_grid_search_parameters_t20.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pds.Regressors = {}\n",
    "# pds.Regressors['Linear Regression']=LinearRegression()\n",
    "pds.Regressors['Random Forest Baseline']=RandomForestRegressor(random_state=43)\n",
    "pds.Regressors['Random Forest RandomSearch']=RandomForestRegressor(random_state=43).set_params(**rf_random_search_parameters)\n",
    "pds.Regressors['Random Forest GridSearch']=RandomForestRegressor(random_state=43).set_params(**rf_grid_search_parameters)\n",
    "# pds.Regressors['Random Forest RandomSearch T20']=RandomForestRegressor(random_state=43).set_params(**rf_random_search_parameters_t20)\n",
    "pds.Regressors['Random Forest GridSearch T20']=RandomForestRegressor(random_state=43).set_params(**rf_grid_search_parameters_t20)\n",
    "# pds.Regressors['Random Forest GridSearch T20 ++']=RandomForestRegressor(random_state=43).set_params(**rf_grid_search_parameters_t20).set_params(**{'n_estimators':150})\n",
    "\n",
    "# display(pds.Regressors['Random Forest GridSearch T20'])\n",
    "\n",
    "feat_ranks = df_feature_ranks.sort_values('Mean Rank')['Feature'].to_list()\n",
    "\n",
    "for t in range(70,0,-10):\n",
    "# for t in range(5,75,10):\n",
    "    k='Top ' + str(t)\n",
    "    tra=filtered_transformer(feat_ranks[:t])\n",
    "    pds.AddPreProc(tra,'pp'+ str(t))\n",
    "    pds.AddQCSet('pp'+ str(t),'RF Tuning Tests')\n",
    "    _ = pds.CalculateScores('RF Tuning Tests','pp'+ str(t),k,X[feat_ranks[:t]],y,verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pds.GetScores(qc_set_keys=['RF Tuning Tests'],metric_keys=['R^2 Score','RMS Error','Mean Absolute Error'],verbose=False)\n",
    "fig,axs=plt.subplots(1,len(pds.active_metrics),figsize=(0.5+5*len(pds.active_metrics),4))  \n",
    "pds.GraphScores(qc_set_key='RF Tuning Tests',axs=axs)\n",
    "\n",
    "\n",
    "# for axs in [axs1,axs2,axs3]:\n",
    "    # axs[0].set_ylim(0.75,1)\n",
    "axs[0].set_ylim(0.015,0.03)\n",
    "axs[1].set_ylim(0.02,0.04)\n",
    "axs[2].set_ylim(0.9,1.0)\n",
    "\n",
    "for ax in axs:\n",
    "    for line in ax.get_lines():\n",
    "        # print(line.get_label())\n",
    "        if line.get_label() in ['_child8','_child6','Random Forest RandomSearch T20','Random Forest GridSearch T20']:\n",
    "            line.set_linestyle('--')\n",
    "    leg=ax.get_legend()\n",
    "    for line in leg.get_lines():\n",
    "        if line.get_label() in ['_child8','_child6','Random Forest RandomSearch T20','Random Forest GridSearch T20']:\n",
    "            line.set_linestyle('--')\n",
    "    ax.set_xlabel('Selected Features')\n",
    "\n",
    "fig.suptitle('Mean Feature Ranking Metrics, Random Forest Hyperparameter Tuning',fontsize=12,fontweight='bold')\n",
    "fig.tight_layout()\n",
    "fig.savefig('./Output Files/Images/Model Tuning/RF_tuning_metrics.png',format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Broad Options Usinbg Random Search:')\n",
    "for k,v in random_grid.items():\n",
    "    print(f'{k}: {v}')\n",
    "# print(random_grid)\n",
    "# pprint.pp(rf_random.best_params_)\n",
    "print('\\nSelected by Random Search:')\n",
    "for k,v in rf_random.best_params_.items():\n",
    "    print(f'{k}: {v}')\n",
    "\n",
    "\n",
    "print('\\nNarrow Options Using Exhaustive (Grid) Search:')\n",
    "for k,v in search_grid.items():\n",
    "    print(f'{k}: {v}')\n",
    "# print(random_grid)\n",
    "# pprint.pp(rf_random.best_params_)\n",
    "print('\\nSelected by Random Search:')\n",
    "for k,v in rf_grid_search_parameters.items():\n",
    "    print(f'{k}: {v}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
