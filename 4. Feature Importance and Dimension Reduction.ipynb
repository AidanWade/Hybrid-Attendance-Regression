{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries import and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "## Common Libray Definitions\n",
    "\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Custom Library Definitions\n",
    "from CustomLibs.CustomFunctions import plot_corr_heatmap, plot_permutation_importance, sqlcol\n",
    "from CustomLibs.CustomTransformers import filtered_transformer\n",
    "from config import Config\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from CustomLibs.MultiPipe import MultiPipe\n",
    "import scipy.stats\n",
    "\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "\n",
    "\n",
    "## SQL Store Definition\n",
    "engine = sqlalchemy.create_engine(Config.CONN_STR)\n",
    "\n",
    "date_val_end=Config.TEST_DATE_CUTOFF\n",
    "date_test_start=pd.to_datetime(date_val_end) + pd.DateOffset(days=1)\n",
    "\n",
    "# lower = 0.0\n",
    "# upper = 2\n",
    "# mu = 0.95\n",
    "# sigma = 0.2\n",
    "\n",
    "# rangen=scipy.stats.truncnorm((lower-mu)/sigma,(upper-mu)/sigma,loc=mu,scale=sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data from SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load silver level, full combined dataset and define X dataframe of independent variables and y series of attendence percentage.\n",
    "with engine.connect() as conn:\n",
    "    df_preproc = pd.read_sql_table('Preprocessed_Features', conn,schema='Gold')\n",
    "\n",
    "df_preproc.columns = [str(x) for x in df_preproc.columns]\n",
    "\n",
    "# df_preproc.info()\n",
    "df_preproc.set_index('Date',inplace=True)\n",
    "\n",
    "label_field = df_preproc.columns[-1]\n",
    "X=df_preproc.sort_index().loc[:date_val_end].drop(columns=label_field)\n",
    "y=df_preproc.sort_index().loc[:date_val_end][label_field]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "corr = spearmanr(X).correlation\n",
    "\n",
    "# Ensure the correlation matrix is symmetric\n",
    "corr = (corr + corr.T) / 2\n",
    "np.fill_diagonal(corr, 1)\n",
    "\n",
    "# We convert the correlation matrix to a distance matrix before performing\n",
    "# hierarchical clustering using Ward's linkage.\n",
    "distance_matrix = 1 - np.abs(corr)\n",
    "# print(distance_matrix.shape)\n",
    "dist_linkage = hierarchy.ward(squareform(distance_matrix))\n",
    "dendro = hierarchy.dendrogram(\n",
    "    dist_linkage, labels=X.columns.to_list(), ax=ax, leaf_rotation=90, color_threshold=0.4, leaf_font_size=8\n",
    ")\n",
    "fig.suptitle('Hierarchical Agglomerative Clustering using Spearman Correlation (Ward Linkage)',fontsize=12,fontweight='bold')\n",
    "fig.tight_layout()\n",
    "fig.savefig('./Output Files/Images/Feature Selection/dendrogram.png',format='png',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "slices=[(0,X.shape[1],X.columns.tolist())]\n",
    "for cut_dist in [x / 10.0 for x in range(1, 12, 1)]:\n",
    "    # create a array of cluster IDs corresponding to each leaf in dendrogram accoridng to cut distance\n",
    "    cluster_ids = hierarchy.fcluster(dist_linkage, cut_dist, criterion=\"distance\")\n",
    "    # Initialise a dictionary of lists\n",
    "    cluster_id_to_feature_ids = defaultdict(list)\n",
    "    # idx is the leaf node index, corresponding to features in, cluster_id is assigned cluster\n",
    "    for idx, cluster_id in enumerate(cluster_ids):\n",
    "        # Get correlation of that feature at col index = idx with the label series (y) \n",
    "        label_corr=abs(X.iloc[:,idx].corr(y,method='spearman'))\n",
    "        # append a tuple for each feature in the cluster containing the feature index and the correlation to label value\n",
    "        cluster_id_to_feature_ids[cluster_id].append((idx,label_corr))\n",
    "    # for each cluster, sort the associated list of tuples (in place) to put (index of) the feature with  largest label correlation first in cluster list\n",
    "    [v.sort(key=lambda x: x[1],reverse=True) for v in cluster_id_to_feature_ids.values()]\n",
    "    # for each cluster, get the feature index (first element of tuple) from the first element of the sort list\n",
    "    selected_features = [v[0][0] for v in cluster_id_to_feature_ids.values()]\n",
    "    # convert features indexs to names applying index selection to the original dataframe\n",
    "    selected_features_names = X.columns[selected_features].tolist()\n",
    "    # update list of slices only the cut has acutally changed the number of selected features\n",
    "    if slices[-1][1]>len(selected_features_names):\n",
    "        slices.append((cut_dist,len(selected_features_names),selected_features_names))\n",
    "\n",
    "\n",
    "pds = MultiPipe()\n",
    "\n",
    "\n",
    "if Config.REGEN_RANKINGS:\n",
    "    feature_ranks={'Spearman':{}}\n",
    "    prev_slice=[]\n",
    "    slices.reverse()\n",
    "    for slice in slices:\n",
    "        current_feats = [x for x in slice[2] if x not in prev_slice]\n",
    "        rank = np.mean(list(range(len(prev_slice)+1,len(slice[2])+1)))\n",
    "        print(f'{rank}:{current_feats}')\n",
    "        # print(list(range(len(prev_slice)+1,len(slice[2])+1)))\n",
    "        for feat in current_feats:\n",
    "            feature_ranks['Spearman'][feat]=rank\n",
    "        prev_slice=slice[2]\n",
    "\n",
    "distances=[]\n",
    "count_att=[]\n",
    "for slice in slices:\n",
    "    print(slice)\n",
    "    distances.append(slice[0])\n",
    "    count_att.append(slice[1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.plot(count_att,distances)\n",
    "ax.set_title('Attributes Per Slice')\n",
    "ax.set_xlabel('Remaining Attributes')\n",
    "ax.set_ylabel('Cut Distance')\n",
    "ax.grid(visible=True,which='Major',axis='both')\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig('./Output Files/Images/Feature Selection/dendrogram_slices.png',format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.REGEN_RANKINGS:\n",
    "    # Extract Feature Importances from tree based regression models\n",
    "    tra=filtered_transformer(X.columns)\n",
    "\n",
    "    for key,reg in [('RF_FI','Random Forest Regressor'),('XGB_FI','XGBoost Regressor')]:\n",
    "        \n",
    "        pipe = make_pipeline(tra,pds.Regressors[reg])\n",
    "        pipe.fit(X,y)\n",
    "\n",
    "        importances=[]\n",
    "        for ori_col in X.columns:\n",
    "            feat_indexes=[]\n",
    "            for i,new_col in enumerate(pipe[0].get_feature_names_out()):\n",
    "                if new_col.startswith(ori_col):\n",
    "                    feat_indexes.append(i)\n",
    "            importances.append((ori_col,sum([pipe[1].feature_importances_[x] for x in feat_indexes])))\n",
    "        importances.sort(key=lambda x: x[1],reverse=True)\n",
    "        # ranks={}\n",
    "        feature_ranks[key]={}\n",
    "        for rnk,feat_name in enumerate(importances,start=1):\n",
    "            feature_ranks[key][feat_name[0]]=rnk\n",
    "\n",
    "        # df_feature_ranks[lab]=[ranks[x] for x in df_feature_ranks['Feature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.REGEN_RANKINGS:\n",
    "    for key,reg in pds.Regressors.items():\n",
    "        # X_train, X_test, y_train, y_test = train_test_split(X[selected_features_names[key]].drop(columns='Desks_Booked'), y, random_state=43,shuffle=True)\n",
    "        # pipe=pds.QC_Set['Spearman Feat Selection']['Scale'][key]\n",
    "        feature_ranks[key]={}\n",
    "        selected_features_names=X.columns.tolist()\n",
    "        \n",
    "        print(key,end=': ')\n",
    "        while len(selected_features_names):\n",
    "            pert_importances=[]\n",
    "            for i, (train_index, test_index) in enumerate(pds.CV.split(X)):\n",
    "                X_train, y_train=X.iloc[train_index],y.iloc[train_index]\n",
    "                X_test, y_test=X.iloc[test_index],y.iloc[test_index]\n",
    "                tra=filtered_transformer(selected_features_names)\n",
    "                pipe=make_pipeline(tra,reg)\n",
    "                pipe.fit(X_train[selected_features_names], y_train)\n",
    "                pert_importance=permutation_importance(pipe,X_test[selected_features_names],y_test,scoring='neg_root_mean_squared_error')\n",
    "                pert_importances.append(pert_importance['importances_mean'])\n",
    "            pert_importance=np.mean(pert_importances,axis=0)\n",
    "            # get index of minimum importance value\n",
    "            least_important=pert_importance.argmin()\n",
    "            # get name of column to drop\n",
    "            least_important=X[selected_features_names].columns[least_important]\n",
    "            # update the rank\n",
    "            feature_ranks[key][least_important]=len(selected_features_names)\n",
    "            selected_features_names.remove(least_important)\n",
    "            print('.',end='')\n",
    "        print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.REGEN_RANKINGS:    \n",
    "    df_feature_ranks=pd.DataFrame(feature_ranks)\n",
    "    df_feature_ranks['Mean Rank']=df_feature_ranks.mean(axis=1)\n",
    "    df_feature_ranks.sort_values('Mean Rank',ascending=True,inplace=True)\n",
    "    df_feature_ranks.reset_index(inplace=True,names='Feature')\n",
    "    with engine.connect() as conn:\n",
    "        df_feature_ranks.to_sql('PermutationFeatureRanks',conn,schema='Gold',if_exists='replace',dtype=sqlcol(df_feature_ranks),index=False)\n",
    "else:\n",
    "    with engine.connect() as conn:\n",
    "        df_feature_ranks = pd.read_sql_table('PermutationFeatureRanks', conn,schema='Gold')\n",
    "df_feature_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats={}\n",
    "for key,val in pds.Regressors.items():\n",
    "    feats[key]=df_feature_ranks.sort_values(key)['Feature'].to_list()\n",
    "feats['Spearman']=df_feature_ranks.sort_values('Spearman')['Feature'].to_list()\n",
    "feats['Mean']=df_feature_ranks.sort_values('Mean Rank')['Feature'].to_list()\n",
    "feats['RF_FI']=df_feature_ranks.sort_values('RF_FI')['Feature'].to_list()\n",
    "feats['XGB_FI']=df_feature_ranks.sort_values('XGB_FI')['Feature'].to_list()\n",
    "\n",
    "\n",
    "for feat_count in range(70,0,-10):\n",
    "    k='Top ' + str(feat_count)\n",
    "\n",
    "    # Spearman\n",
    "    tra=filtered_transformer(feats['Spearman'][:feat_count])\n",
    "    pds.AddPreProc(tra,'pp'+ k)\n",
    "    pds.AddQCSet('pp'+ k,'Spearman Feat Ranking')\n",
    "    _ = pds.CalculateScores('Spearman Feat Ranking','pp'+ k,k,X[feats['Spearman'][:feat_count]],y,verbose=False)\n",
    "    \n",
    "    # Mean\n",
    "    tra=filtered_transformer(feats['Mean'][:feat_count])\n",
    "    pds.AddPreProc(tra,'pp'+ k)\n",
    "    pds.AddQCSet('pp'+ k,'Mean Feat Ranking')\n",
    "    _ = pds.CalculateScores('Mean Feat Ranking','pp'+ k,k,X[feats['Mean'][:feat_count]],y,verbose=False)\n",
    "\n",
    "\n",
    "    pds.Regressors['RF_FI']=pds.Regressors['Random Forest Regressor']\n",
    "    pds.Regressors['XGB_FI']=pds.Regressors['XGBoost Regressor']\n",
    "    # Individual - Perturbation\n",
    "    for key,reg in pds.Regressors.items():\n",
    "        tra=filtered_transformer(feats[key][:feat_count])\n",
    "        pds.AddPreProc(tra,'pp'+ k)\n",
    "        pds.AddQCSet('pp'+ k,'Regressor Feat Ranking',regs={key:reg}.items())\n",
    "        _ = pds.CalculateScores('Regressor Feat Ranking','pp'+ k,k,X[feats[key][:feat_count]],y,reg_filter=[key],verbose=False)\n",
    "\n",
    "    # Individual - Tree Feat Importances\n",
    "    # for label,key in [('RF_FI','Random Forest Regressor'),('XGB_FI','XGBoost Regressor')]:\n",
    "    #     # pds.Regressors[label]=(label,pds.Regressors[key])\n",
    "    #     tra=filtered_transformer(feats[label][:feat_count])\n",
    "    #     pds.AddPreProc(tra,'pp'+ k)\n",
    "    #     pds.AddQCSet('pp'+ k,'Tree Feat Importance',regs={label:pds.Regressors[key]}.items())\n",
    "    #     _ = pds.CalculateScores('Tree Feat Importance','pp'+ k,k,X[feats[label][:feat_count]],y,reg_filter=[label],verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pds.GetScores(reg_keys=['Linear Regression','Random Forest Regressor','XGBoost Regressor','Linear SVR'] ,metric_keys=['R^2 Score','RMS Error','Mean Absolute Error'],verbose=False)\n",
    "fig1,axs1=plt.subplots(1,len(pds.active_metrics),figsize=(0.5+5*len(pds.active_metrics),4))  \n",
    "pds.GraphScores('Spearman Feat Ranking',axs=axs1)\n",
    "\n",
    "fig2,axs2=plt.subplots(1,len(pds.active_metrics),figsize=(0.5+5*len(pds.active_metrics),4))  \n",
    "pds.GraphScores('Mean Feat Ranking',axs2)\n",
    "\n",
    "\n",
    "\n",
    "_ = pds.GetScores(metric_keys=['R^2 Score','RMS Error','Mean Absolute Error'],verbose=False)\n",
    "fig3,axs3=plt.subplots(1,len(pds.active_metrics),figsize=(0.5+5*len(pds.active_metrics),4))  \n",
    "pds.GraphScores('Regressor Feat Ranking',axs3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# _ = pds.GetScores(reg_keys=['RF_FI','XGB_FI'] ,metric_keys=['R^2 Score','RMS Error','Mean Absolute Error'],verbose=False)\n",
    "# fig4,axs4=plt.subplots(1,len(pds.active_metrics),figsize=(0.5+5*len(pds.active_metrics),4))  \n",
    "# pds.GraphScores('Tree Feat Importance',axs4)\n",
    "# fig4.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for axs in [axs1,axs2,axs3]:\n",
    "    # axs[0].set_ylim(0.75,1)\n",
    "    axs[0].set_ylim(0.015,0.035)\n",
    "    axs[1].set_ylim(0.02,0.045)\n",
    "    axs[2].set_ylim(0.85,1.0)\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel('Selected Features',fontsize=11)\n",
    "        # ax.set_ylabel(f'Metric Value',fontsize=11)\n",
    "        # ax.tick_params(axis='x', labelrotation=45, labelsize=10)\n",
    "        # ax.tick_params(axis='y', labelsize=10)\n",
    "\n",
    "# axs1[2].set_ylim(0.85,1.00)\n",
    "\n",
    "for ax in axs3:\n",
    "    for line in ax.get_lines():\n",
    "        # print(line.get_label())\n",
    "        if line.get_label() in ['_child8','_child10','RF_FI','XGB_FI']:\n",
    "            line.set_linestyle('--')\n",
    "    leg=ax.get_legend()\n",
    "    for line in leg.get_lines():\n",
    "        if line.get_label() in ['_child8','_child10','RF_FI','XGB_FI']:\n",
    "            line.set_linestyle('--')\n",
    "\n",
    "fig1.suptitle('HAC Feature Ranking Metrics',fontsize=12,fontweight='bold')\n",
    "fig1.tight_layout()\n",
    "fig1.savefig('./Output Files/Images/Feature Selection/HAC_ranking_metrics.png',format='png',bbox_inches='tight')\n",
    "fig2.suptitle('Mean Feature Ranking Metrics',fontsize=12,fontweight='bold')\n",
    "fig2.tight_layout()\n",
    "fig2.savefig('./Output Files/Images/Feature Selection/mean_ranking_metrics.png',format='png',bbox_inches='tight')\n",
    "fig3.suptitle('Model Specific Feature Ranking Metrics',fontsize=12,fontweight='bold')\n",
    "fig3.tight_layout()\n",
    "fig3.savefig('./Output Files/Images/Feature Selection/indi_ranking_metrics.png',format='png',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(X).correlation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.absolute(spearmanr(X).correlation)\n",
    "(np.sum(corr)-corr.shape[0])/(corr.shape[0]-1)**2\n",
    "np.mean(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_ranks.columns[1:]\n",
    "correlation_reduction={}\n",
    "for method in df_feature_ranks.columns[1:]:\n",
    "    feat_list = df_feature_ranks.sort_values(method,ascending=False)['Feature'].to_list()\n",
    "    correlation_reduction[method]={}\n",
    "    for i in range(len(feat_list)-2):\n",
    "        remaining_feats=feat_list[i:]\n",
    "        corr = np.absolute(spearmanr(X[remaining_feats]).correlation)\n",
    "        correlation_reduction[method][len(remaining_feats)]=(np.sum(corr)-corr.shape[0])/(corr.shape[0]-1)**2\n",
    "df_correlation_reduction = pd.DataFrame.from_dict(correlation_reduction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for column in df_correlation_reduction:\n",
    "    ax.plot(df_correlation_reduction[column],label=column)\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
