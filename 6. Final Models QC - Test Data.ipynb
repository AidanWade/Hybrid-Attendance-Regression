{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "## Common Libray Definitions\n",
    "\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Custom Library Definitions\n",
    "from CustomLibs.CustomFunctions import plot_corr_heatmap, plot_permutation_importance, sqlcol,save_to_file,load_from_file\n",
    "from config import Config\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler,SplineTransformer,OneHotEncoder\n",
    "from datetime import datetime\n",
    "from CustomLibs.CustomTransformers import filtered_transformer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from CustomLibs.MultiPipe import MultiPipe\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error,root_mean_squared_error,r2_score\n",
    "from pprint import pprint\n",
    "import xgboost as xgb\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "## SQL Store Definition\n",
    "engine = sqlalchemy.create_engine(Config.CONN_STR)\n",
    "\n",
    "date_val_end=Config.TEST_DATE_CUTOFF\n",
    "date_test_start=pd.to_datetime(date_val_end) + pd.DateOffset(days=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    df_preproc = pd.read_sql_table('Preprocessed_Features', conn,schema='Gold')\n",
    "    df_feature_ranks = pd.read_sql_table('PermutationFeatureRanks', conn,schema='Gold')\n",
    "df_preproc.columns = [str(x) for x in df_preproc.columns]\n",
    "df_preproc.set_index('Date',inplace=True)\n",
    "label_field = df_preproc.columns[-1]\n",
    "\n",
    "\n",
    "# colorder = df_preproc.columns.tolist()\n",
    "# for i,val in enumerate(colorder):\n",
    "#     if val=='Month':\n",
    "#         break\n",
    "# neworder=colorder[:i] + ['Quarter'] + colorder[i+1:]\n",
    "# df_preproc['Quarter']=(df_preproc.index.month//4)+1\n",
    "# df_preproc=df_preproc[neworder]\n",
    "# print(df_preproc.columns.tolist())\n",
    "# df_preproc['Month']=(df_preproc.index.month//4)+1\n",
    "\n",
    "X=df_preproc.sort_index().loc[:date_val_end].drop(columns=label_field)\n",
    "y=df_preproc[label_field].sort_index().loc[:date_val_end]\n",
    "\n",
    "X_test=df_preproc.sort_index().loc[date_test_start:].drop(columns=label_field)\n",
    "y_test=df_preproc[label_field].sort_index().loc[date_test_start:]\n",
    "\n",
    "feat_ranks = df_feature_ranks.sort_values('Mean Rank')['Feature'].to_list()\n",
    "\n",
    "rf_random_search_parameters = load_from_file('rf_random_search_parameters')\n",
    "rf_grid_search_parameters = load_from_file('rf_grid_search_parameters')\n",
    "rf_random_search_parameters_t60 = load_from_file('rf_random_search_parameters_t60')\n",
    "rf_grid_search_parameters_t60 = load_from_file('rf_grid_search_parameters_t60')\n",
    "rf_random_search_parameters_t20 = load_from_file('rf_random_search_parameters_t20')\n",
    "rf_grid_search_parameters_t20 = load_from_file('rf_grid_search_parameters_t20')\n",
    "xgb_gs1_parameters = load_from_file('xgb_gs1_parameters')\n",
    "xgb_gs2_parameters = load_from_file('xgb_gs2_parameters')\n",
    "xgb_gs3_parameters = load_from_file('xgb_gs3_parameters')\n",
    "xgb_gs4_parameters = load_from_file('xgb_gs4_parameters')\n",
    "xgb_gs5_parameters = load_from_file('xgb_gs5_parameters')\n",
    "svr_gs1_parameters = load_from_file('svr_gs1_parameters')\n",
    "svr_gs1_parameters_t20 = load_from_file('svr_gs2_parameters_t20')\n",
    "ridge_gs1_parameters = load_from_file('ridge_gs1_parameters')\n",
    "ridge_gs1_parameters_t20 = load_from_file('ridge_gs1_parameters_t20')\n",
    "\n",
    "# print([type(x) for x in X.columns])\n",
    "\n",
    "pds=MultiPipe()\n",
    "pds.Regressors = {}\n",
    "pds.Regressors['Random Forest Baseline']=RandomForestRegressor(random_state=43)\n",
    "pds.Regressors['Random Forest RandomSearch']=RandomForestRegressor(random_state=43).set_params(**rf_random_search_parameters)\n",
    "pds.Regressors['Random Forest GridSearch']=RandomForestRegressor(random_state=43).set_params(**rf_grid_search_parameters)\n",
    "# pds.Regressors['Random Forest GridSearch 20 MF0.8']=RandomForestRegressor(random_state=43)\n",
    "pds.Regressors['Random Forest GridSearch 20']=RandomForestRegressor(random_state=43)\n",
    "pds.Regressors['Random Forest Baseline 20']=RandomForestRegressor(random_state=43)\n",
    "pds.Regressors['XGBoost Baseline'] = xgb.XGBRegressor()\n",
    "pds.Regressors['XGBoost GS5']=xgb.XGBRegressor().set_params(**xgb_gs5_parameters).set_params(**xgb_gs2_parameters).set_params(**xgb_gs3_parameters).set_params(**xgb_gs4_parameters)\n",
    "pds.Regressors['Linear Regression']=LinearRegression()\n",
    "pds.Regressors['Linear Ridge']=Ridge().set_params(**ridge_gs1_parameters)\n",
    "pds.Regressors['Linear Ridge 20']=Ridge()\n",
    "# pds.Regressors['Linear Regression 30']=LinearRegression()\n",
    "pds.Regressors['SVR Baseline'] = LinearSVR(random_state=43,max_iter=20000)\n",
    "pds.Regressors['SVR GridSearch']=LinearSVR(random_state=43,max_iter=20000).set_params(**svr_gs1_parameters)\n",
    "pds.Regressors['SVR GridSearch_manual']=LinearSVR(random_state=43,max_iter=20000).set_params(**{'C': 0.1,'epsilon': 0,'loss': 'squared_epsilon_insensitive'})\n",
    "pds.Regressors['SVR GridSearch 20']=LinearSVR(random_state=43,max_iter=20000)\n",
    "\n",
    "tra=filtered_transformer(feat_ranks)\n",
    "tra20=filtered_transformer(feat_ranks[:20])\n",
    "tra30=filtered_transformer(feat_ranks[:30])\n",
    "tra40=filtered_transformer(feat_ranks[:40])\n",
    "tra60=filtered_transformer(feat_ranks[:60])\n",
    "\n",
    "pds.AddPreProc(tra,'pp')\n",
    "pds.PurgeQCSet('Test Data')\n",
    "pds.AddQCSet('pp','Test Data')\n",
    "# pds.QC_Set['Test Data']['pp']['Linear Regression 30']=make_pipeline(tra30,LinearRegression())\n",
    "pds.QC_Set['Test Data']['pp']['Random Forest GridSearch 20']=make_pipeline(tra20,RandomForestRegressor(random_state=43).set_params(**rf_grid_search_parameters_t20))\n",
    "pds.QC_Set['Test Data']['pp']['Random Forest Baseline 20']=make_pipeline(tra20,RandomForestRegressor(random_state=43))\n",
    "# pds.QC_Set['Test Data']['pp']['Random Forest GridSearch 20 MF0.8']=make_pipeline(tra20,RandomForestRegressor(random_state=43).set_params(**rf_grid_search_parameters_t20).set_params(**{'max_features':0.6}))\n",
    "# pds.QC_Set['Test Data']['pp']['Random Forest GridSearch 60']=make_pipeline(tra60,RandomForestRegressor(random_state=43).set_params(**rf_grid_search_parameters_t60))\n",
    "pds.QC_Set['Test Data']['pp']['SVR GridSearch 20']=make_pipeline(tra20,LinearSVR(random_state=43).set_params(**svr_gs1_parameters_t20))\n",
    "pds.QC_Set['Test Data']['pp']['Linear Ridge 20']=make_pipeline(tra20,Ridge().set_params(**ridge_gs1_parameters_t20))\n",
    "\n",
    "# print(feat_ranks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_parameters=[rf_grid_search_parameters_t20]\n",
    "for param_set in rf_parameters:\n",
    "    for k,v in param_set.items():\n",
    "        print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_parameters=[xgb_gs5_parameters,xgb_gs2_parameters,xgb_gs3_parameters,xgb_gs4_parameters]\n",
    "for param_set in xgboost_parameters:\n",
    "    for k,v in param_set.items():\n",
    "        print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# X_test=X_test[10:]\n",
    "# y_test=y_test[10:]\n",
    "\n",
    "# Initialise result dataframe\n",
    "df_results = y_test.to_frame('Actual')\n",
    "df_results['3 Day Mean'] = X_test['PctOnSite_ma3']\n",
    "\n",
    "days = ['Monday','Tuesday','Wednesday','Thursday','Friday']\n",
    "\n",
    "# for i,(key,reg) in enumerate(pds.Regressors.items()):\n",
    "    # pipe=make_pipeline(tra,reg)\n",
    "    \n",
    "for i,(key,pipe) in enumerate(pds.QC_Set['Test Data']['pp'].items()):\n",
    "    print(f'{key}')\n",
    "    if key in ['Random Forest GridSearch 20','Random Forest GridSearch 20 MF0.8', 'Random Forest Baseline 20']:\n",
    "        pipe.fit(X[feat_ranks[:20]],y)\n",
    "        y_pred = pd.Series(pipe.predict(X_test[feat_ranks[:20]]),y_test.index)\n",
    "    elif key == 'Linear Ridge 20':\n",
    "        pipe.fit(X[feat_ranks[:20]],y)\n",
    "        y_pred = pd.Series(pipe.predict(X_test[feat_ranks[:20]]),y_test.index)\n",
    "    elif key == 'SVR GridSearch 20':\n",
    "        pipe.fit(X[feat_ranks[:20]],y)\n",
    "        y_pred = pd.Series(pipe.predict(X_test[feat_ranks[:20]]),y_test.index)\n",
    "    else:\n",
    "        pipe.fit(X,y)\n",
    "        y_pred = pd.Series(pipe.predict(X_test),y_test.index)\n",
    "    # y_pred = reg.predict(X_test)\n",
    "    df_results[key] = y_pred\n",
    "    mae=mean_absolute_error(y_test,y_pred)\n",
    "    rms=root_mean_squared_error(y_test,y_pred)\n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    print(f'    Overall'.ljust(35,' ') + f'MAE: {mae:.4f}, RMS: {rms:.4f}, R2: {r2:4f}')\n",
    "    # print(len(y_test))\n",
    "    for day in range(1,6):\n",
    "        \n",
    "        mae=mean_absolute_error(y_test.loc[X_test['Day_Of_Week']==day],y_pred.loc[X_test['Day_Of_Week']==day])\n",
    "        rms=root_mean_squared_error(y_test.loc[X_test['Day_Of_Week']==day],y_pred.loc[X_test['Day_Of_Week']==day])\n",
    "        r2=r2_score(y_test.loc[X_test['Day_Of_Week']==day],y_pred.loc[X_test['Day_Of_Week']==day])\n",
    "        print(f'    {days[day-1]}'.ljust(35,' ') + f'MAE: {mae:.4f}, RMS: {rms:.4f}, R2: {r2:4f}')\n",
    "        # print(len(y_test.loc[X_test['Day_Of_Week']==day]))\n",
    "\n",
    "\n",
    "\n",
    "print(f'3 Day Mean'.ljust(28,' ') + f\"MAE: {mean_absolute_error(y_test,X_test['PctOnSite_ma3']):.4f}, RMS: {root_mean_squared_error(y_test,X_test['PctOnSite_ma3']):.4f}, R2: {r2_score(y_test,X_test['PctOnSite_ma3']):4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    df_access_by_directorate = pd.read_sql_table('Moving_Averages_By_Directorate', conn,schema='Gold')\n",
    "    df_preproc = pd.read_sql_table('Preprocessed_Features', conn,schema='Gold')\n",
    "\n",
    "label_field = df_preproc.columns[-1]\n",
    "feat_to_be_replaced = [x for x in df_preproc.columns if x.startswith('PctOnSite_')]\n",
    "feat_not_imported = [x for x in df_access_by_directorate.columns if x.startswith('PctOnSite_')]\n",
    "feat_not_imported = [x for x in feat_not_imported if x not in feat_to_be_replaced]\n",
    "\n",
    "df_preproc.drop(columns=feat_to_be_replaced,inplace=True)\n",
    "df_preproc.rename(columns={'Pct_On_Site':'Pct_On_Site_Overall','Desks_Booked':'Desks_Booked_Overall'},inplace=True)\n",
    "df_access_by_directorate.drop(columns=feat_not_imported+['Day_Name','Desks_Used'],inplace=True)\n",
    "# df_access_by_directorate.columns = [x.replace('PctOnSite_m','m') for x in df_access_by_directorate.columns]\n",
    "df_preproc_by_directorate=df_preproc.merge(right=df_access_by_directorate,how='left',on='Date').drop(columns='Pct_On_Site_Overall')\n",
    "\n",
    "df_preproc_by_directorate= df_preproc_by_directorate.rename(str,axis=\"columns\") \n",
    "\n",
    "\n",
    "\n",
    "directorates=df_preproc_by_directorate['Directorate'].unique()\n",
    "# df_preproc_by_directorate=df_preproc_by_directorate.set_index(['Directorate','Date']).sort_index()\n",
    "df_preproc_by_directorate=df_preproc_by_directorate.set_index('Date').sort_index()\n",
    "\n",
    "df_grouped_by_directorate=df_preproc_by_directorate.groupby('Directorate')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i,(key,pipe) in enumerate(pds.QC_Set['Test Data']['pp'].items()):\n",
    "    print(f'{key}')\n",
    "    y_pred_by_dir=[]\n",
    "    total_staff_by_dir=[]\n",
    "    for directorate, df_g in df_grouped_by_directorate:\n",
    "        # print(X.columns)\n",
    "\n",
    "        if key == 'Random Forest GridSearch 20':\n",
    "            X=df_g.loc[:date_val_end,feat_ranks[:20]]\n",
    "            X_test=df_g.loc[date_test_start:,feat_ranks[:20]]\n",
    "        elif key == 'Linear Regression 30':\n",
    "            X=df_g.loc[:date_val_end,feat_ranks[:30]]\n",
    "            X_test=df_g.loc[date_test_start:,feat_ranks[:30]]\n",
    "        elif key == 'SVR GridSearch 30':\n",
    "            X=df_g.loc[:date_val_end,feat_ranks[:30]]\n",
    "            X_test=df_g.loc[date_test_start:,feat_ranks[:30]]\n",
    "        else:\n",
    "            X=df_g.loc[:date_val_end].drop(columns=[label_field,'Directorate'])\n",
    "            X_test=df_g.loc[date_test_start:].drop(columns=[label_field,'Directorate'])\n",
    "\n",
    "        # X=df_g.loc[:date_val_end].drop(columns=[label_field,'Directorate'])\n",
    "        y=df_g[label_field].loc[:date_val_end]\n",
    "        \n",
    "        # X_test=df_g.loc[date_test_start:].drop(columns=[label_field,'Directorate'])\n",
    "        y_test=df_g[label_field].loc[date_test_start:]\n",
    "\n",
    "\n",
    "        X.columns = X.columns.astype(str)\n",
    "        pipe.fit(X,y)\n",
    "        y_pred = pd.Series(pipe.predict(X_test),y_test.index)\n",
    "\n",
    "        y_pred_by_dir.append(y_pred * df_g.loc[date_test_start:,'Directorate_Numbers'])\n",
    "        total_staff_by_dir.append(df_g.loc[date_test_start:,'Directorate_Numbers'])\n",
    "\n",
    "        mae=mean_absolute_error(y_test,y_pred)\n",
    "        rms=root_mean_squared_error(y_test,y_pred)\n",
    "        r2=r2_score(y_test,y_pred)\n",
    "        # print(f'    {directorate}'.ljust(40,' ') + f'MAE: {mae:.4f}, RMS: {rms:.4f}, R2: {r2:4f}')\n",
    "\n",
    "    y_test=df_preproc.set_index('Date')['Pct_On_Site_Overall'].sort_index().loc[date_test_start:]\n",
    "    y_pred_sum_of_dir = pd.Series(np.sum(y_pred_by_dir,axis=0),index=y_pred_by_dir[0].index)\n",
    "    total_staff = pd.Series(np.sum(total_staff_by_dir,axis=0),index=total_staff_by_dir[0].index)\n",
    "    y_pred_pct=y_pred_sum_of_dir/total_staff\n",
    "    df_results[key + ' ByDir']=y_pred_pct.to_list()\n",
    "    # print(y_pred_pct)\n",
    "\n",
    "    mae=mean_absolute_error(y_test,y_pred_pct)\n",
    "    rms=root_mean_squared_error(y_test,y_pred_pct)\n",
    "    r2=r2_score(y_test,y_pred_pct)\n",
    "\n",
    "    print(f'        Overall'.ljust(40,' ') + f'MAE: {mae:.4f}, RMS: {rms:.4f}, R2: {r2:4f}')\n",
    "\n",
    "df_results['Booked_Pct']=np.NaN\n",
    "df_results['Booked_Pct']=df_preproc.set_index('Date')['Desks_Booked_Overall'].sort_index().loc[date_test_start:]/total_staff\n",
    "\n",
    "mae=mean_absolute_error(y_test,df_results['Booked_Pct'])\n",
    "rms=root_mean_squared_error(y_test,df_results['Booked_Pct'])\n",
    "r2=r2_score(y_test,df_results['Booked_Pct'])\n",
    "\n",
    "print(f'    Booked Accuracy'.ljust(40,' ') + f'MAE: {mae:.4f}, RMS: {rms:.4f}, R2: {r2:4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae=mean_absolute_error(y_test,df_results['Booked_Pct'])\n",
    "rms=root_mean_squared_error(y_test,df_results['Booked_Pct'])\n",
    "r2=r2_score(y_test,df_results['Booked_Pct'])\n",
    "\n",
    "print(f'    Booked Accuracy'.ljust(40,' ') + f'MAE: {mae:.4f}, RMS: {rms:.4f}, R2: {r2:4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_labels=df_results.columns.tolist()[1:]\n",
    "df_results.reset_index(inplace=True)\n",
    "df_results['Week_Number']=df_results['Date'].dt.isocalendar().week\n",
    "df_results['Week_Start'] = df_results['Date'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "df_results['Day_Name']=df_results['Date'].dt.day_name()\n",
    "\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_results.to_sql('TestSet_Predictions',conn,schema='Gold',if_exists='replace',dtype=sqlcol(df_results),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(df,args):\n",
    "    true_label=args[0]\n",
    "    pred_labels=args[1]\n",
    "    result = {\n",
    "        'MAE':{},\n",
    "        'RMS':{},\n",
    "        'R^2':{}\n",
    "    }\n",
    "\n",
    "\n",
    "    for pred_label in pred_labels:\n",
    "        result['MAE'][pred_label]=mean_absolute_error(df[true_label],df[pred_label])\n",
    "        result['RMS'][pred_label]=root_mean_squared_error(df[true_label],df[pred_label])\n",
    "        result['R^2'][pred_label]=r2_score(df[true_label],df[pred_label])\n",
    "\n",
    "    return pd.DataFrame.from_dict(result)\n",
    "\n",
    "\n",
    "\n",
    "df_metrics_byday = df_results.groupby('Day_Name').apply(get_scores,('Actual',regressor_labels),include_groups=False)\n",
    "\n",
    "df_results['dummy'] = 1\n",
    "df_metrics_all = df_results.groupby('dummy').apply(get_scores,('Actual',regressor_labels),include_groups=False).reset_index().drop(columns='dummy').rename(columns={'level_1':'Model'}).set_index('Model')\n",
    "display(df_metrics_all.sort_values('RMS').head(40))\n",
    "\n",
    "ts_list=df_metrics_all.sort_values('RMS').index[:4].to_list()\n",
    "ts_list=ts_list[:2]+[ts_list[3]]\n",
    "\n",
    "# df_metrics_byday\n",
    "\n",
    "df_metrics_byweek = df_results[ts_list+['3 Day Mean','Week_Start','Actual']].groupby('Week_Start').apply(get_scores,('Actual',ts_list+['3 Day Mean']),include_groups=False)\n",
    "# df_metrics_byweek.head(10)\n",
    "\n",
    "\n",
    "df_results['dummy'] = 1\n",
    "df_metrics_all = df_results.groupby('dummy').apply(get_scores,('Actual',regressor_labels),include_groups=False).reset_index().drop(columns='dummy').rename(columns={'level_1':'Model'}).set_index('Model')\n",
    "df_metrics_all.sort_values('RMS').head(40)\n",
    "\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_metrics_all.reset_index().to_sql('TestSet_Metrics',conn,schema='Gold',if_exists='replace',index=False,dtype=sqlcol(df_results))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_sublist=df_metrics_all.sort_values('RMS').index[:4].to_list()\n",
    "regressor_sublist=regressor_sublist[:2]+[regressor_sublist[3]]+['3 Day Mean']\n",
    "\n",
    "\n",
    "fig,axs=plt.subplots(2,1,figsize=(10,6),sharex=True)  \n",
    "\n",
    "for i,day in enumerate(['Wednesday','Thursday']):\n",
    "# for i,day in enumerate(['Monday','Tuesday','Wednesday','Thursday','Friday']):\n",
    "    df=df_results.loc[df_results['Day_Name']==day].set_index('Date')\n",
    "    sns.lineplot(data=df[regressor_sublist+['Actual']] ,ax=axs[i],linestyle='-')\n",
    "    axs[i].set_title(f'Predicted Versus Actual: {day}',fontsize=11)\n",
    "    axs[i].legend(loc='upper left')\n",
    "    axs[i].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    # axs[i].tick_params(axis='x', labelrotation=45, labelsize=10)\n",
    "    axs[i].grid(visible=True,which='Major',axis='both') \n",
    "    # axs[i].set_ylim(0,0.6)\n",
    "    axs[i].set_yticklabels([])\n",
    "    axs[i].tick_params(axis='x', labelrotation=45, labelsize=10)\n",
    "    axs[i].set_ylabel('Staff On Site')\n",
    "fig.suptitle('Predicted versus Actual - Test Data',fontsize=12,fontweight='bold')\n",
    "fig.tight_layout()\n",
    "fig.savefig('./Output Files/Images/Final/top_model_timeseries.png',format='png',bbox_inches='tight')\n",
    "\n",
    "for ax in axs:\n",
    "    for line in ax.get_lines():\n",
    "        # print(line.get_label())\n",
    "        if line.get_label() not in ['_child8','_child6','3 Day Mean','Actual']:\n",
    "            line.set_linestyle('-')\n",
    "    leg=ax.get_legend()\n",
    "    for line in leg.get_lines():\n",
    "        if line.get_label() not in ['_child8','_child6','3 Day Mean','Actual']:\n",
    "            line.set_linestyle('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs=plt.subplots(3,1,figsize=(10,8),sharex=True)\n",
    "\n",
    "for i,metric in enumerate(['MAE','RMS','R^2']):\n",
    "    # sns.lineplot(data=df_metrics_byweek[~df_metrics_byweek.index.isin(['7 Day Mean'], level=1)],x=df_metrics_byweek[~df_metrics_byweek.index.isin(['7 Day Mean'], level=1)].index.get_level_values(0),y=metric,hue=df_metrics_byweek[~df_metrics_byweek.index.isin(['7 Day Mean'], level=1)].index.get_level_values(1),ax=axs[i])\n",
    "    sns.lineplot(data=df_metrics_byweek,x=df_metrics_byweek.index.get_level_values(0),y=metric,hue=df_metrics_byweek.index.get_level_values(1),ax=axs[i])\n",
    "    axs[i].legend(loc='upper left').set_title('')\n",
    "    axs[i].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    # axs[i].tick_params(axis='x', labelrotation=45, labelsize=10)\n",
    "    axs[i].grid(visible=True,which='Major',axis='y') \n",
    "    axs[i].set_ylabel(f'{metric} Value',fontsize=11)\n",
    "    axs[i].set_xlabel(f'Date',fontsize=11)\n",
    "    axs[i].tick_params(axis='x', labelrotation=45, labelsize=10)\n",
    "    axs[i].tick_params(axis='y', labelsize=10)\n",
    "    axs[i].set_title(f'{metric} Calculated Per Week',fontsize=12)\n",
    "\n",
    "axs[0].set_ylim(0.0,0.25)\n",
    "axs[1].set_ylim(0.0,0.25)\n",
    "axs[2].set_ylim(0.0,1.1)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.vlines(datetime(2023,10,2), 0, 1, colors='tab:green', linestyles=':', label='')\n",
    "    ax.vlines(datetime(2023,10,30), 0, 1, colors='tab:green', linestyles=':', label='')\n",
    "    ax.vlines(datetime(2024,1,1), 0, 1, colors='tab:green', linestyles=':', label='')\n",
    "    ax.vlines(datetime(2023,11,13), 0, 1, colors='tab:red', linestyles=':', label='')\n",
    "    ax.vlines(datetime(2023,10,9), 0, 1, colors='tab:red', linestyles=':', label='')\n",
    "fig.suptitle('Prediction Metrics By Week - Test Data',fontsize=12,fontweight='bold')\n",
    "fig.tight_layout()\n",
    "fig.savefig('./Output Files/Images/Final/top_model_weekly_err.png',format='png',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_metrics_all_ex1day = df_results.loc[~(df_results['Date'].isin(['2023-10-9','2023-10-12']))].groupby('dummy').apply(get_scores,('Actual',regressor_labels),include_groups=False).reset_index().drop(columns='dummy').rename(columns={'level_1':'Model'}).set_index('Model')\n",
    "display(df_metrics_all_ex1day.sort_values('RMS').head(40))\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_metrics_all_ex1day.reset_index().to_sql('TestSet_Metrics_excl',conn,schema='Gold',if_exists='replace',index=False,dtype=sqlcol(df_metrics_all_ex1day))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing without Desks Booked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe = pds.QC_Set['Test Data']['pp']['XGBoost GS5']\n",
    "\n",
    "y_pred_by_dir=[]\n",
    "total_staff_by_dir=[]\n",
    "for directorate, df_g in df_grouped_by_directorate:\n",
    "\n",
    "    X=df_g.loc[:date_val_end].drop(columns=[label_field,'Directorate','Desks_Booked'])\n",
    "    X_test=df_g.loc[date_test_start:].drop(columns=[label_field,'Directorate','Desks_Booked'])\n",
    "\n",
    "    # X=df_g.loc[:date_val_end].drop(columns=[label_field,'Directorate'])\n",
    "    y=df_g[label_field].loc[:date_val_end]\n",
    "    \n",
    "    # X_test=df_g.loc[date_test_start:].drop(columns=[label_field,'Directorate'])\n",
    "    y_test=df_g[label_field].loc[date_test_start:]\n",
    "\n",
    "\n",
    "    X.columns = X.columns.astype(str)\n",
    "    pipe.fit(X,y)\n",
    "    y_pred = pd.Series(pipe.predict(X_test),y_test.index)\n",
    "\n",
    "    y_pred_by_dir.append(y_pred * df_g.loc[date_test_start:,'Directorate_Numbers'])\n",
    "    total_staff_by_dir.append(df_g.loc[date_test_start:,'Directorate_Numbers'])\n",
    "\n",
    "    mae=mean_absolute_error(y_test,y_pred)\n",
    "    rms=root_mean_squared_error(y_test,y_pred)\n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    # print(f'    {directorate}'.ljust(40,' ') + f'MAE: {mae:.4f}, RMS: {rms:.4f}, R2: {r2:4f}')\n",
    "\n",
    "y_test=df_preproc.set_index('Date')['Pct_On_Site_Overall'].sort_index().loc[date_test_start:]\n",
    "y_pred_sum_of_dir = pd.Series(np.sum(y_pred_by_dir,axis=0),index=y_pred_by_dir[0].index)\n",
    "total_staff = pd.Series(np.sum(total_staff_by_dir,axis=0),index=total_staff_by_dir[0].index)\n",
    "y_pred_pct=y_pred_sum_of_dir/total_staff\n",
    "\n",
    "# print(y_pred_pct)\n",
    "\n",
    "mae=mean_absolute_error(y_test.loc[~(y_test.index=='2023-10-12')],y_pred_pct.loc[~(y_test.index=='2023-10-12')])\n",
    "rms=root_mean_squared_error(y_test.loc[~(y_test.index=='2023-10-12')],y_pred_pct.loc[~(y_test.index=='2023-10-12')])\n",
    "r2=r2_score(y_test.loc[~(y_test.index=='2023-10-12')],y_pred_pct.loc[~(y_test.index=='2023-10-12')])\n",
    "\n",
    "print(f'        Overall'.ljust(40,' ') + f'MAE: {mae:.4f}, RMS: {rms:.4f}, R2: {r2:4f}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
