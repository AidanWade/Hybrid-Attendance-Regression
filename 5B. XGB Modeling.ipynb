{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "## Common Libray Definitions\n",
    "\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Custom Library Definitions\n",
    "from CustomLibs.CustomFunctions import plot_corr_heatmap, plot_permutation_importance, sqlcol,save_to_file,load_from_file\n",
    "from config import Config\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler,SplineTransformer,OneHotEncoder\n",
    "\n",
    "from CustomLibs.CustomTransformers import filtered_transformer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from CustomLibs.MultiPipe import MultiPipe\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error,root_mean_squared_error,r2_score\n",
    "import scipy.stats\n",
    "\n",
    "## SQL Store Definition\n",
    "engine = sqlalchemy.create_engine(Config.CONN_STR)\n",
    "\n",
    "date_val_end=Config.TEST_DATE_CUTOFF\n",
    "date_test_start=pd.to_datetime(date_val_end) + pd.DateOffset(days=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    df_preproc = pd.read_sql_table('Preprocessed_Features', conn,schema='Gold')\n",
    "    df_feature_ranks = pd.read_sql_table('PermutationFeatureRanks', conn,schema='Gold')\n",
    "\n",
    "df_preproc.set_index('Date',inplace=True)\n",
    "df_preproc.columns = [str(x) for x in df_preproc.columns]\n",
    "label_field = df_preproc.columns[-1]\n",
    "\n",
    "X=df_preproc.sort_index().loc[:date_val_end].drop(columns=label_field)\n",
    "y=df_preproc[label_field].sort_index().loc[:date_val_end]\n",
    "\n",
    "X_test=df_preproc.sort_index().loc[date_test_start:].drop(columns=label_field)\n",
    "y_test=df_preproc[label_field].sort_index().loc[date_test_start:]\n",
    "\n",
    "feat_ranks = df_feature_ranks.sort_values('Mean Rank')['Feature'].to_list()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit:\n",
    "# https://randomrealizations.com/posts/xgboost-parameter-tuning-with-optuna/\n",
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "# https://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/\n",
    "# https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f\n",
    "\n",
    "\n",
    "pds=MultiPipe()\n",
    "\n",
    "\n",
    "xgb_pipe = make_pipeline(filtered_transformer(feat_ranks),xgb.XGBRegressor())\n",
    "\n",
    "search_grid_1 = {\n",
    "    'xgbregressor__learning_rate': [0.1,0.2,0.3],\n",
    "    'xgbregressor__n_estimators': [100, 500, 1000],\n",
    "    # 'xgbregressor__max_depth':  [3,5,7],\n",
    "    # 'xgbregressor__min_child_weight': [1,5,9],\n",
    "    'xgbregressor__tree_method':['hist'],\n",
    "    'xgbregressor__objective':['reg:squarederror'],\n",
    "    'xgbregressor__eval_metric':['rmse'],\n",
    "    'xgbregressor__seed':[43]\n",
    "    }\n",
    "\n",
    "print(search_grid_1)\n",
    "scoring = {'Mean Absolute Error': 'neg_mean_absolute_error', 'RMS Error': 'neg_root_mean_squared_error','R^2 Score':'r2'}\n",
    "\n",
    "if Config.REGEN_GRID_SEARCH_XGB:\n",
    "    xgb_gridsearch = GridSearchCV(xgb_pipe, search_grid_1, scoring=scoring, refit='RMS Error',cv=pds.CV,n_jobs=-1,verbose=10)\n",
    "    xgb_gridsearch.fit(X, y)\n",
    "    xgb_gs1_parameters={}\n",
    "    for p,v in xgb_gridsearch.best_params_.items():\n",
    "        xgb_gs1_parameters[p.replace('xgbregressor__','')]=v\n",
    "    save_to_file(xgb_gs1_parameters,'xgb_gs1_parameters')\n",
    "\n",
    "else:\n",
    "    xgb_gs1_parameters = load_from_file('xgb_gs1_parameters')\n",
    "\n",
    "# print(xgb_gs1_parameters)\n",
    "\n",
    "\n",
    "for k,v in xgb_gs1_parameters.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipe = make_pipeline(filtered_transformer(feat_ranks),xgb.XGBRegressor(seed=43).set_params(**xgb_gs1_parameters).set_params(**xgb_gs5_parameters))\n",
    "\n",
    "search_grid_2 = {\n",
    "    'xgbregressor__max_depth':  [3,5,7,9],\n",
    "    'xgbregressor__min_child_weight': [1,3,5,7,9],\n",
    "    'xgbregressor__gamma':[i/10.0 for i in range(0,5)]\n",
    "    }\n",
    "    \n",
    "for k,v in search_grid_2.items():\n",
    "    print(f'{k}: {v}')\n",
    "\n",
    "scoring = {'Mean Absolute Error': 'neg_mean_absolute_error', 'RMS Error': 'neg_root_mean_squared_error','R^2 Score':'r2'}\n",
    "\n",
    "if Config.REGEN_GRID_SEARCH_XGB:\n",
    "    xgb_gridsearch = GridSearchCV(xgb_pipe, search_grid_2, scoring=scoring, refit='RMS Error',cv=pds.CV,n_jobs=-1,verbose=10)\n",
    "    xgb_gridsearch.fit(X, y)\n",
    "    xgb_gs2_parameters={}\n",
    "    for p,v in xgb_gridsearch.best_params_.items():\n",
    "        xgb_gs2_parameters[p.replace('xgbregressor__','')]=v\n",
    "    save_to_file(xgb_gs2_parameters,'xgb_gs2_parameters')\n",
    "\n",
    "else:\n",
    "    xgb_gs2_parameters = load_from_file('xgb_gs2_parameters')\n",
    "\n",
    "# print(xgb_gs2_parameters)\n",
    "\n",
    "for k,v in xgb_gs2_parameters.items():\n",
    "    print(f'{k}: {v}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipe = make_pipeline(filtered_transformer(feat_ranks),xgb.XGBRegressor(seed=43).set_params(**xgb_gs1_parameters).set_params(**xgb_gs2_parameters))\n",
    "\n",
    "search_grid_3 = {\n",
    "    'xgbregressor__subsample':  [0.9,1],\n",
    "    'xgbregressor__colsample_bynode': [0.8,0.9,1],\n",
    "    }\n",
    "    \n",
    "for k,v in search_grid_3.items():\n",
    "    print(f'{k}: {v}')\n",
    "\n",
    "scoring = {'Mean Absolute Error': 'neg_mean_absolute_error', 'RMS Error': 'neg_root_mean_squared_error','R^2 Score':'r2'}\n",
    "\n",
    "if Config.REGEN_GRID_SEARCH_XGB:\n",
    "    xgb_gridsearch = GridSearchCV(xgb_pipe, search_grid_3, scoring=scoring, refit='RMS Error',cv=pds.CV,n_jobs=-1,verbose=10)\n",
    "    xgb_gridsearch.fit(X, y)\n",
    "    xgb_gs3_parameters={}\n",
    "    for p,v in xgb_gridsearch.best_params_.items():\n",
    "        xgb_gs3_parameters[p.replace('xgbregressor__','')]=v\n",
    "    save_to_file(xgb_gs3_parameters,'xgb_gs3_parameters')\n",
    "\n",
    "else:\n",
    "    xgb_gs3_parameters = load_from_file('xgb_gs3_parameters')\n",
    "\n",
    "# print(xgb_gs3_parameters)\n",
    "\n",
    "for k,v in xgb_gs3_parameters.items():\n",
    "    print(f'{k}: {v}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipe = make_pipeline(filtered_transformer(feat_ranks),xgb.XGBRegressor(seed=43).set_params(**xgb_gs1_parameters).set_params(**xgb_gs2_parameters).set_params(**xgb_gs3_parameters))\n",
    "\n",
    "search_grid_4 = {\n",
    "    'xgbregressor__reg_alpha':[0, 0.05, 0.2,0.5,1,2],\n",
    "    'xgbregressor__reg_lambda':[0, 0.05, 0.2,0.5,1,2],\n",
    "    }\n",
    "    \n",
    "for k,v in search_grid_4.items():\n",
    "    print(f'{k}: {v}')\n",
    "\n",
    "scoring = {'Mean Absolute Error': 'neg_mean_absolute_error', 'RMS Error': 'neg_root_mean_squared_error','R^2 Score':'r2'}\n",
    "\n",
    "if Config.REGEN_GRID_SEARCH_XGB:\n",
    "    xgb_gridsearch = GridSearchCV(xgb_pipe, search_grid_4, scoring=scoring, refit='RMS Error',cv=pds.CV,n_jobs=-1,verbose=10)\n",
    "    xgb_gridsearch.fit(X, y)\n",
    "    xgb_gs4_parameters={}\n",
    "    for p,v in xgb_gridsearch.best_params_.items():\n",
    "        xgb_gs4_parameters[p.replace('xgbregressor__','')]=v\n",
    "    save_to_file(xgb_gs4_parameters,'xgb_gs4_parameters')\n",
    "\n",
    "else:\n",
    "    xgb_gs4_parameters = load_from_file('xgb_gs4_parameters')\n",
    "\n",
    "# print(xgb_gs4_parameters)\n",
    "\n",
    "for k,v in xgb_gs4_parameters.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipe = make_pipeline(filtered_transformer(feat_ranks),xgb.XGBRegressor().set_params(**xgb_gs1_parameters).set_params(**xgb_gs2_parameters).set_params(**xgb_gs3_parameters).set_params(**xgb_gs4_parameters))\n",
    "\n",
    "search_grid_5 = {\n",
    "    'xgbregressor__learning_rate': [0.01,0.05,0.1,0.2],\n",
    "    'xgbregressor__n_estimators': [100, 500, 1000, 2000],\n",
    "    }\n",
    "    \n",
    "for k,v in search_grid_5.items():\n",
    "    print(f'{k}: {v}')\n",
    "\n",
    "scoring = {'Mean Absolute Error': 'neg_mean_absolute_error', 'RMS Error': 'neg_root_mean_squared_error','R^2 Score':'r2'}\n",
    "\n",
    "if Config.REGEN_GRID_SEARCH_XGB:\n",
    "    xgb_gridsearch = GridSearchCV(xgb_pipe, search_grid_5, scoring=scoring, refit='RMS Error',cv=pds.CV,n_jobs=-1,verbose=10)\n",
    "    xgb_gridsearch.fit(X, y)\n",
    "    xgb_gs5_parameters={}\n",
    "    for p,v in xgb_gridsearch.best_params_.items():\n",
    "        xgb_gs5_parameters[p.replace('xgbregressor__','')]=v\n",
    "    save_to_file(xgb_gs5_parameters,'xgb_gs5_parameters')\n",
    "\n",
    "else:\n",
    "    xgb_gs5_parameters = load_from_file('xgb_gs5_parameters')\n",
    "\n",
    "# print(xgb_gs5_parameters)\n",
    "\n",
    "for k,v in xgb_gs5_parameters.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list=[xgb_gs1_parameters,xgb_gs2_parameters,xgb_gs3_parameters,xgb_gs4_parameters,xgb_gs5_parameters]\n",
    "print(params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# pds.AddPreProc(filtered_transformer(feat_ranks),'preproc')\n",
    "pds.Regressors={}\n",
    "pds.Regressors['XGBoost Baseline'] = xgb.XGBRegressor()\n",
    "pds.Regressors['XGBoost GS1']=xgb.XGBRegressor().set_params(**xgb_gs1_parameters)\n",
    "pds.Regressors['XGBoost GS2']=xgb.XGBRegressor().set_params(**xgb_gs1_parameters).set_params(**xgb_gs2_parameters)\n",
    "pds.Regressors['XGBoost GS3']=xgb.XGBRegressor().set_params(**xgb_gs1_parameters).set_params(**xgb_gs2_parameters).set_params(**xgb_gs3_parameters)\n",
    "pds.Regressors['XGBoost GS4']=xgb.XGBRegressor().set_params(**xgb_gs1_parameters).set_params(**xgb_gs2_parameters).set_params(**xgb_gs3_parameters).set_params(**xgb_gs4_parameters)\n",
    "pds.Regressors['XGBoost GS5']=xgb.XGBRegressor().set_params(**xgb_gs1_parameters).set_params(**xgb_gs2_parameters).set_params(**xgb_gs3_parameters).set_params(**xgb_gs4_parameters).set_params(**xgb_gs4_parameters)\n",
    "# pds.CalculateScores('XGBoost Tuning','preproc','Models',X,y)\n",
    "# _ = pds.GetScores(qc_set_keys=['XGBoost Tuning'],metric_keys=['R^2 Score','RMS Error','Mean Absolute Error'],verbose=False)\n",
    "\n",
    "# for a in _:\n",
    "#     print(a)\n",
    "\n",
    "feat_ranks = df_feature_ranks.sort_values('Mean Rank')['Feature'].to_list()\n",
    "\n",
    "for t in range(70,0,-10):\n",
    "# for t in range(5,75,10):\n",
    "    k='Top ' + str(t)\n",
    "    tra=filtered_transformer(feat_ranks[:t])\n",
    "    pds.AddPreProc(tra,'pp'+ str(t))\n",
    "    pds.AddQCSet('pp'+ str(t),'XGB Tuning Tests')\n",
    "    _ = pds.CalculateScores('XGB Tuning Tests','pp'+ str(t),k,X[feat_ranks[:t]],y,verbose=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp = pds.GetScores(qc_set_keys=['XGB Tuning Tests'],metric_keys=['R^2 Score','RMS Error','Mean Absolute Error'],verbose=False)\n",
    "fig,axs=plt.subplots(1,len(pds.active_metrics),figsize=(0.5+5*len(pds.active_metrics),4))  \n",
    "pds.GraphScores(qc_set_key='XGB Tuning Tests',axs=axs)\n",
    "fig.tight_layout()\n",
    "\n",
    "axs[0].set_ylim(0.015,0.035)\n",
    "axs[1].set_ylim(0.02,0.045)\n",
    "axs[2].set_ylim(0.85,1.0)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('Selected Features')\n",
    "    # for line in ax.get_lines():\n",
    "    #     # print(line.get_label())\n",
    "    #     if line.get_label() in ['_child8','_child10','Random Forest RandomSearch T60','Random Forest GridSearch T60']:\n",
    "    #         line.set_linestyle('--')\n",
    "    # leg=ax.get_legend()\n",
    "    # for line in leg.get_lines():\n",
    "    #     if line.get_label() in ['_child8','_child10','Random Forest RandomSearch T60','Random Forest GridSearch T60']:\n",
    "    #         line.set_linestyle('--')\n",
    "fig.suptitle('Mean Feature Ranking Metrics, XGBoost Hyperparameter Tuning',fontsize=12,fontweight='bold')\n",
    "fig.tight_layout()\n",
    "fig.savefig('./Output Files/Images/Model Tuning/XGB_tuning_metrics.png',format='png',bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
